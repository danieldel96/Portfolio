{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e445362b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing_score loss: 1.5965251127878826\n",
      "testing_score accuracy: 0.3710015167792638\n"
     ]
    }
   ],
   "source": [
    "#baum_300_sigmoid\n",
    "import numpy as np\n",
    "load = np.load('data/baum_300_sigmoid.npz',allow_pickle=True)\n",
    "\n",
    "training_score = load['x']\n",
    "testing_score = load['y']\n",
    "\n",
    "training_score = np.transpose(training_score)\n",
    "testing_score = np.transpose(testing_score)\n",
    "\n",
    "\n",
    "print('testing_score loss:', np.mean(testing_score[0]))\n",
    "print('testing_score accuracy:',np.mean(testing_score[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7eed7cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing_score loss: 1.6178172032038372\n",
      "testing_score accuracy: 0.3749220321575801\n"
     ]
    }
   ],
   "source": [
    "#baum_300_softmax\n",
    "import numpy as np\n",
    "load = np.load('data/baum_300_softmax.npz',allow_pickle=True)\n",
    "\n",
    "training_score = load['x']\n",
    "testing_score = load['y']\n",
    "\n",
    "training_score = np.transpose(training_score)\n",
    "testing_score = np.transpose(testing_score)\n",
    "\n",
    "\n",
    "print('testing_score loss:', np.mean(testing_score[0]))\n",
    "print('testing_score accuracy:',np.mean(testing_score[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66f2b24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing_score loss: 0.2088899090886116\n",
      "testing_score accuracy: 0.8076388736565908\n"
     ]
    }
   ],
   "source": [
    "#ravdess_300_sigmoid\n",
    "import numpy as np\n",
    "load = np.load('data/ravdess_300_sigmoid.npz',allow_pickle=True)\n",
    "\n",
    "training_score = load['x']\n",
    "testing_score = load['y']\n",
    "\n",
    "training_score = np.transpose(training_score)\n",
    "testing_score = np.transpose(testing_score)\n",
    "\n",
    "\n",
    "print('testing_score loss:', np.mean(testing_score[0]))\n",
    "print('testing_score accuracy:',np.mean(testing_score[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "509ede8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing_score loss: 0.19432383030653\n",
      "testing_score accuracy: 0.7944444417953491\n"
     ]
    }
   ],
   "source": [
    "#ravdess_300_softmax\n",
    "import numpy as np\n",
    "load = np.load('data/ravdess_300_softmax.npz',allow_pickle=True)\n",
    "\n",
    "training_score = load['x']\n",
    "testing_score = load['y']\n",
    "\n",
    "training_score = np.transpose(training_score)\n",
    "testing_score = np.transpose(testing_score)\n",
    "\n",
    "\n",
    "print('testing_score loss:', np.mean(testing_score[0]))\n",
    "print('testing_score accuracy:',np.mean(testing_score[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29073b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.23872889578342438, 0.8775981664657593], 'training accuracy fold #0']\n",
      "[[1.0916067361831665, 0.3333333432674408], 'testing accuracy fold #0']\n",
      "[[ 0  0  0  2  1  0]\n",
      " [ 1  4  1  6  4  3]\n",
      " [ 0  0  1  1  3  0]\n",
      " [ 3  6  2 14  4  2]\n",
      " [ 4  1  0  4  8  2]\n",
      " [ 2  2  1  2  1  2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.31      0.21      0.25        19\n",
      "           2       0.20      0.20      0.20         5\n",
      "           3       0.48      0.45      0.47        31\n",
      "           4       0.38      0.42      0.40        19\n",
      "           5       0.22      0.20      0.21        10\n",
      "\n",
      "    accuracy                           0.33        87\n",
      "   macro avg       0.27      0.25      0.25        87\n",
      "weighted avg       0.36      0.33      0.34        87\n",
      "\n",
      "[[0.2626546323299408, 0.8729792237281799], 'training accuracy fold #1']\n",
      "[[1.0240159034729004, 0.4137931168079376], 'testing accuracy fold #1']\n",
      "[[ 2  0  1  3  1  1]\n",
      " [ 0  4  2  0  2  0]\n",
      " [ 1  1  2  0  2  0]\n",
      " [ 1  4  9 17  0  3]\n",
      " [ 4  0  1  7 11  1]\n",
      " [ 2  0  1  3  1  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.25      0.22         8\n",
      "           1       0.44      0.50      0.47         8\n",
      "           2       0.12      0.33      0.18         6\n",
      "           3       0.57      0.50      0.53        34\n",
      "           4       0.65      0.46      0.54        24\n",
      "           5       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.41        87\n",
      "   macro avg       0.33      0.34      0.32        87\n",
      "weighted avg       0.47      0.41      0.43        87\n",
      "\n",
      "[[0.2530635595321655, 0.8799076080322266], 'training accuracy fold #2']\n",
      "[[1.0392616987228394, 0.3563218414783478], 'testing accuracy fold #2']\n",
      "[[ 5  0  2  3  2  0]\n",
      " [ 0  3  7  3  2  0]\n",
      " [ 0  2  2  1  0  0]\n",
      " [ 2  6  1 13  1  2]\n",
      " [ 2  4  2  1  7  3]\n",
      " [ 2  3  0  1  4  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.42      0.43        12\n",
      "           1       0.17      0.20      0.18        15\n",
      "           2       0.14      0.40      0.21         5\n",
      "           3       0.59      0.52      0.55        25\n",
      "           4       0.44      0.37      0.40        19\n",
      "           5       0.17      0.09      0.12        11\n",
      "\n",
      "    accuracy                           0.36        87\n",
      "   macro avg       0.33      0.33      0.32        87\n",
      "weighted avg       0.39      0.36      0.36        87\n",
      "\n",
      "[[0.2627737522125244, 0.8752886652946472], 'training accuracy fold #3']\n",
      "[[1.0581732988357544, 0.3218390941619873], 'testing accuracy fold #3']\n",
      "[[ 2  2  1  2  2  2]\n",
      " [ 1  2  2  1  2  0]\n",
      " [ 0  3  2  0  3  2]\n",
      " [ 1  1  3 11  4  7]\n",
      " [ 1  2  5  4 10  5]\n",
      " [ 0  0  0  1  2  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.18      0.25        11\n",
      "           1       0.20      0.25      0.22         8\n",
      "           2       0.15      0.20      0.17        10\n",
      "           3       0.58      0.41      0.48        27\n",
      "           4       0.43      0.37      0.40        27\n",
      "           5       0.06      0.25      0.10         4\n",
      "\n",
      "    accuracy                           0.32        87\n",
      "   macro avg       0.30      0.28      0.27        87\n",
      "weighted avg       0.40      0.32      0.35        87\n",
      "\n",
      "[[0.25409427285194397, 0.861751139163971], 'training accuracy fold #4']\n",
      "[[1.0617330074310303, 0.2906976640224457], 'testing accuracy fold #4']\n",
      "[[ 0  2  1  2  4  1]\n",
      " [ 0  2  2  7  6  3]\n",
      " [ 0  1  1  0  2  0]\n",
      " [ 3  5  1 13  6  1]\n",
      " [ 4  1  0  3  9  2]\n",
      " [ 0  1  1  2  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        10\n",
      "           1       0.17      0.10      0.12        20\n",
      "           2       0.17      0.25      0.20         4\n",
      "           3       0.48      0.45      0.46        29\n",
      "           4       0.33      0.47      0.39        19\n",
      "           5       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.29        86\n",
      "   macro avg       0.19      0.21      0.20        86\n",
      "weighted avg       0.28      0.29      0.28        86\n",
      "\n",
      "[[0.2804560661315918, 0.8709677457809448], 'training accuracy fold #5']\n",
      "[[1.0917125940322876, 0.302325576543808], 'testing accuracy fold #5']\n",
      "[[ 3  3  1  5  0  0]\n",
      " [ 0  1  3  3  1  2]\n",
      " [ 0  1  2  2  1  1]\n",
      " [ 3  3  1 14  4  1]\n",
      " [ 5  4  2  9  5  1]\n",
      " [ 0  1  0  1  2  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.25      0.26        12\n",
      "           1       0.08      0.10      0.09        10\n",
      "           2       0.22      0.29      0.25         7\n",
      "           3       0.41      0.54      0.47        26\n",
      "           4       0.38      0.19      0.26        26\n",
      "           5       0.17      0.20      0.18         5\n",
      "\n",
      "    accuracy                           0.30        86\n",
      "   macro avg       0.26      0.26      0.25        86\n",
      "weighted avg       0.32      0.30      0.30        86\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#baum 30 sigomoid\n",
    "import pickle\n",
    "with (open('pickle_files/baum_30_sigmoid.pckl', \"rb\")) as openfile:\n",
    "    while True:\n",
    "        try:\n",
    "            print(pickle.load(openfile))\n",
    "        except EOFError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfbc69c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.25092217326164246, 0.8729792237281799], 'training accuracy fold #0']\n",
      "[[1.0814522504806519, 0.3218390941619873], 'testing accuracy fold #0']\n",
      "[[ 0  1  0  1  1  0]\n",
      " [ 1  4  1  7  4  2]\n",
      " [ 0  0  2  2  1  0]\n",
      " [ 5  4  5 12  4  1]\n",
      " [ 3  1  2  3  8  2]\n",
      " [ 1  1  1  3  2  2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.36      0.21      0.27        19\n",
      "           2       0.18      0.40      0.25         5\n",
      "           3       0.43      0.39      0.41        31\n",
      "           4       0.40      0.42      0.41        19\n",
      "           5       0.29      0.20      0.24        10\n",
      "\n",
      "    accuracy                           0.32        87\n",
      "   macro avg       0.28      0.27      0.26        87\n",
      "weighted avg       0.36      0.32      0.33        87\n",
      "\n",
      "[[0.2753412425518036, 0.886836051940918], 'training accuracy fold #1']\n",
      "[[1.044571042060852, 0.4597701132297516], 'testing accuracy fold #1']\n",
      "[[ 1  1  1  2  2  1]\n",
      " [ 0  5  1  0  2  0]\n",
      " [ 1  1  2  0  2  0]\n",
      " [ 1  5  4 18  4  2]\n",
      " [ 4  3  1  0 14  2]\n",
      " [ 2  0  1  2  2  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.12      0.12         8\n",
      "           1       0.33      0.62      0.43         8\n",
      "           2       0.20      0.33      0.25         6\n",
      "           3       0.82      0.53      0.64        34\n",
      "           4       0.54      0.58      0.56        24\n",
      "           5       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.46        87\n",
      "   macro avg       0.33      0.37      0.33        87\n",
      "weighted avg       0.52      0.46      0.47        87\n",
      "\n",
      "[[0.2939968407154083, 0.8683602809906006], 'training accuracy fold #2']\n",
      "[[1.131374478340149, 0.3333333432674408], 'testing accuracy fold #2']\n",
      "[[ 4  2  3  0  1  2]\n",
      " [ 1  3  7  1  3  0]\n",
      " [ 0  2  2  1  0  0]\n",
      " [ 1  6  3 12  1  2]\n",
      " [ 2  4  1  1  7  4]\n",
      " [ 2  3  0  1  4  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.33      0.36        12\n",
      "           1       0.15      0.20      0.17        15\n",
      "           2       0.12      0.40      0.19         5\n",
      "           3       0.75      0.48      0.59        25\n",
      "           4       0.44      0.37      0.40        19\n",
      "           5       0.11      0.09      0.10        11\n",
      "\n",
      "    accuracy                           0.33        87\n",
      "   macro avg       0.33      0.31      0.30        87\n",
      "weighted avg       0.41      0.33      0.36        87\n",
      "\n",
      "[[0.26060134172439575, 0.8683602809906006], 'training accuracy fold #3']\n",
      "[[1.0387866497039795, 0.28735631704330444], 'testing accuracy fold #3']\n",
      "[[ 3  2  1  2  1  2]\n",
      " [ 2  1  2  1  2  0]\n",
      " [ 0  3  2  0  3  2]\n",
      " [ 3  2  2 10  4  6]\n",
      " [ 2  6  4  3  9  3]\n",
      " [ 0  1  0  0  3  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.27      0.29        11\n",
      "           1       0.07      0.12      0.09         8\n",
      "           2       0.18      0.20      0.19        10\n",
      "           3       0.62      0.37      0.47        27\n",
      "           4       0.41      0.33      0.37        27\n",
      "           5       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.29        87\n",
      "   macro avg       0.26      0.22      0.23        87\n",
      "weighted avg       0.39      0.29      0.32        87\n",
      "\n",
      "[[0.23039685189723969, 0.8755760192871094], 'training accuracy fold #4']\n",
      "[[1.0166395902633667, 0.3604651093482971], 'testing accuracy fold #4']\n",
      "[[ 1  2  1  1  4  1]\n",
      " [ 1  4  1  7  5  2]\n",
      " [ 0  1  1  0  1  1]\n",
      " [ 2  4  3 16  4  0]\n",
      " [ 4  1  0  3  9  2]\n",
      " [ 0  2  0  2  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.10      0.11        10\n",
      "           1       0.29      0.20      0.24        20\n",
      "           2       0.17      0.25      0.20         4\n",
      "           3       0.55      0.55      0.55        29\n",
      "           4       0.39      0.47      0.43        19\n",
      "           5       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.36        86\n",
      "   macro avg       0.25      0.26      0.25        86\n",
      "weighted avg       0.36      0.36      0.36        86\n",
      "\n",
      "[[0.24038907885551453, 0.8640552759170532], 'training accuracy fold #5']\n",
      "[[0.9223774671554565, 0.3488371968269348], 'testing accuracy fold #5']\n",
      "[[ 2  3  1  4  2  0]\n",
      " [ 0  2  3  3  1  1]\n",
      " [ 1  2  2  1  1  0]\n",
      " [ 3  3  0 16  2  2]\n",
      " [ 5  4  2  8  7  0]\n",
      " [ 0  1  2  0  1  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.17      0.17        12\n",
      "           1       0.13      0.20      0.16        10\n",
      "           2       0.20      0.29      0.24         7\n",
      "           3       0.50      0.62      0.55        26\n",
      "           4       0.50      0.27      0.35        26\n",
      "           5       0.25      0.20      0.22         5\n",
      "\n",
      "    accuracy                           0.35        86\n",
      "   macro avg       0.29      0.29      0.28        86\n",
      "weighted avg       0.37      0.35      0.35        86\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#baum 30 softmax\n",
    "import pickle\n",
    "with (open('pickle_files/baum_30_softmax.pckl', \"rb\")) as openfile:\n",
    "    while True:\n",
    "        try:\n",
    "            print(pickle.load(openfile))\n",
    "        except EOFError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ebe9796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.3336029648780823, 0.8650000095367432], 'training accuracy fold #0']\n",
      "[[0.43974587321281433, 0.7833333611488342], 'testing accuracy fold #0']\n",
      "[[15  0  0  1  0  1  0  0]\n",
      " [ 0 32  0  2  1  1  0  2]\n",
      " [ 0  0 22  3  1  4  0  2]\n",
      " [ 2  0  2 19  5  2  0  0]\n",
      " [ 0  0  0  1 27  2  1  0]\n",
      " [ 2  2  0  0  2 20  2  0]\n",
      " [ 0  0  0  2  2  1 25  0]\n",
      " [ 0  0  2  0  1  1  2 28]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.88      0.83        17\n",
      "           2       0.94      0.84      0.89        38\n",
      "           3       0.85      0.69      0.76        32\n",
      "           4       0.68      0.63      0.66        30\n",
      "           5       0.69      0.87      0.77        31\n",
      "           6       0.62      0.71      0.67        28\n",
      "           7       0.83      0.83      0.83        30\n",
      "           8       0.88      0.82      0.85        34\n",
      "\n",
      "    accuracy                           0.78       240\n",
      "   macro avg       0.79      0.79      0.78       240\n",
      "weighted avg       0.79      0.78      0.78       240\n",
      "\n",
      "[[0.3640603721141815, 0.8683333396911621], 'training accuracy fold #1']\n",
      "[[0.518981397151947, 0.7791666388511658], 'testing accuracy fold #1']\n",
      "[[19  0  0  0  1  0  0  0]\n",
      " [ 0 20  0  0  0  3  0  0]\n",
      " [ 0  1 29  0  5  1  1  1]\n",
      " [ 0  0  0 28  4  0  3  0]\n",
      " [ 0  0  0  0 23  5  2  0]\n",
      " [ 0  0  0  0  2 21  3  6]\n",
      " [ 0  0  4  0  5  0 27  1]\n",
      " [ 0  1  0  0  2  0  2 20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.95      0.97        20\n",
      "           2       0.91      0.87      0.89        23\n",
      "           3       0.88      0.76      0.82        38\n",
      "           4       1.00      0.80      0.89        35\n",
      "           5       0.55      0.77      0.64        30\n",
      "           6       0.70      0.66      0.68        32\n",
      "           7       0.71      0.73      0.72        37\n",
      "           8       0.71      0.80      0.75        25\n",
      "\n",
      "    accuracy                           0.78       240\n",
      "   macro avg       0.81      0.79      0.80       240\n",
      "weighted avg       0.80      0.78      0.79       240\n",
      "\n",
      "[[0.38745933771133423, 0.8700000047683716], 'training accuracy fold #2']\n",
      "[[0.4780464172363281, 0.8333333134651184], 'testing accuracy fold #2']\n",
      "[[12  0  0  1  0  1  0  0]\n",
      " [ 2 28  1  0  0  2  2  0]\n",
      " [ 2  0 26  0  0  3  2  0]\n",
      " [ 0  0  0 23  3  0  2  1]\n",
      " [ 0  0  0  2 28  0  0  0]\n",
      " [ 0  0  0  2  5 17  1  0]\n",
      " [ 0  0  1  0  1  1 32  0]\n",
      " [ 1  0  0  0  2  2  0 34]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.86      0.77        14\n",
      "           2       1.00      0.80      0.89        35\n",
      "           3       0.93      0.79      0.85        33\n",
      "           4       0.82      0.79      0.81        29\n",
      "           5       0.72      0.93      0.81        30\n",
      "           6       0.65      0.68      0.67        25\n",
      "           7       0.82      0.91      0.86        35\n",
      "           8       0.97      0.87      0.92        39\n",
      "\n",
      "    accuracy                           0.83       240\n",
      "   macro avg       0.83      0.83      0.82       240\n",
      "weighted avg       0.85      0.83      0.84       240\n",
      "\n",
      "[[0.3808315396308899, 0.8766666650772095], 'training accuracy fold #3']\n",
      "[[0.5687376856803894, 0.7541666626930237], 'testing accuracy fold #3']\n",
      "[[ 8  2  0  0  2  0  0  0]\n",
      " [ 2 19  0  0  5  3  0  0]\n",
      " [ 0  0 30  0  3  1  1  1]\n",
      " [ 0  0  2 25  5  4  2  5]\n",
      " [ 0  0  2  0 35  2  0  0]\n",
      " [ 0  0  0  0  5 22  1  1]\n",
      " [ 0  0  0  0  4  0 15  0]\n",
      " [ 0  2  0  0  3  1  0 27]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.67      0.73        12\n",
      "           2       0.83      0.66      0.73        29\n",
      "           3       0.88      0.83      0.86        36\n",
      "           4       1.00      0.58      0.74        43\n",
      "           5       0.56      0.90      0.69        39\n",
      "           6       0.67      0.76      0.71        29\n",
      "           7       0.79      0.79      0.79        19\n",
      "           8       0.79      0.82      0.81        33\n",
      "\n",
      "    accuracy                           0.75       240\n",
      "   macro avg       0.79      0.75      0.76       240\n",
      "weighted avg       0.80      0.75      0.76       240\n",
      "\n",
      "[[0.37923336029052734, 0.8824999928474426], 'training accuracy fold #4']\n",
      "[[0.5216128826141357, 0.8041666746139526], 'testing accuracy fold #4']\n",
      "[[ 9  2  0  0  1  1  0  1]\n",
      " [ 1 38  1  2  2  2  0  0]\n",
      " [ 0  2 16  0  1  1  1  0]\n",
      " [ 0  0  0 18  1  1  1  3]\n",
      " [ 0  0  1  0 17  4  6  0]\n",
      " [ 0  0  0  1  1 31  2  1]\n",
      " [ 0  0  0  4  1  0 34  0]\n",
      " [ 0  0  0  1  0  1  0 30]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.64      0.75        14\n",
      "           2       0.90      0.83      0.86        46\n",
      "           3       0.89      0.76      0.82        21\n",
      "           4       0.69      0.75      0.72        24\n",
      "           5       0.71      0.61      0.65        28\n",
      "           6       0.76      0.86      0.81        36\n",
      "           7       0.77      0.87      0.82        39\n",
      "           8       0.86      0.94      0.90        32\n",
      "\n",
      "    accuracy                           0.80       240\n",
      "   macro avg       0.81      0.78      0.79       240\n",
      "weighted avg       0.81      0.80      0.80       240\n",
      "\n",
      "[[0.36661601066589355, 0.8691666722297668], 'training accuracy fold #5']\n",
      "[[0.5512071251869202, 0.7916666865348816], 'testing accuracy fold #5']\n",
      "[[15  0  0  2  1  1  0  0]\n",
      " [ 2 16  0  0  1  1  0  1]\n",
      " [ 0  0 27  0  3  1  0  1]\n",
      " [ 0  0  1 23  3  0  0  4]\n",
      " [ 0  0  0  0 31  1  0  2]\n",
      " [ 0  0  0  2  3 31  1  5]\n",
      " [ 0  0  0  2  6  0 24  0]\n",
      " [ 0  0  0  3  1  2  0 23]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.79      0.83        19\n",
      "           2       1.00      0.76      0.86        21\n",
      "           3       0.96      0.84      0.90        32\n",
      "           4       0.72      0.74      0.73        31\n",
      "           5       0.63      0.91      0.75        34\n",
      "           6       0.84      0.74      0.78        42\n",
      "           7       0.96      0.75      0.84        32\n",
      "           8       0.64      0.79      0.71        29\n",
      "\n",
      "    accuracy                           0.79       240\n",
      "   macro avg       0.83      0.79      0.80       240\n",
      "weighted avg       0.82      0.79      0.80       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#ravdess 30 sigmoid\n",
    "import pickle\n",
    "with (open('pickle_files/ravdess_30_sigmoid.pckl', \"rb\")) as openfile:\n",
    "    while True:\n",
    "        try:\n",
    "            print(pickle.load(openfile))\n",
    "        except EOFError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "598b317e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.38627323508262634, 0.8650000095367432], 'training accuracy fold #0']\n",
      "[[0.5373510718345642, 0.7708333134651184], 'testing accuracy fold #0']\n",
      "[[15  0  0  1  0  1  0  0]\n",
      " [ 0 32  1  3  0  1  0  1]\n",
      " [ 0  2 19  1  1  2  0  7]\n",
      " [ 2  0  0 21  4  2  0  1]\n",
      " [ 0  0  0  6 23  2  0  0]\n",
      " [ 2  2  0  0  2 20  2  0]\n",
      " [ 0  1  0  0  1  3 25  0]\n",
      " [ 0  0  0  0  1  1  2 30]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.88      0.83        17\n",
      "           2       0.86      0.84      0.85        38\n",
      "           3       0.95      0.59      0.73        32\n",
      "           4       0.66      0.70      0.68        30\n",
      "           5       0.72      0.74      0.73        31\n",
      "           6       0.62      0.71      0.67        28\n",
      "           7       0.86      0.83      0.85        30\n",
      "           8       0.77      0.88      0.82        34\n",
      "\n",
      "    accuracy                           0.77       240\n",
      "   macro avg       0.78      0.77      0.77       240\n",
      "weighted avg       0.78      0.77      0.77       240\n",
      "\n",
      "[[0.40076854825019836, 0.8741666674613953], 'training accuracy fold #1']\n",
      "[[0.5688838362693787, 0.7875000238418579], 'testing accuracy fold #1']\n",
      "[[19  0  0  0  1  0  0  0]\n",
      " [ 3 17  0  0  0  3  0  0]\n",
      " [ 0  0 31  0  6  1  0  0]\n",
      " [ 0  0  0 28  4  3  0  0]\n",
      " [ 0  0  0  0 23  4  3  0]\n",
      " [ 0  0  1  0  2 25  3  1]\n",
      " [ 0  0  0  0  7  3 27  0]\n",
      " [ 0  0  0  0  2  1  3 19]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.95      0.90        20\n",
      "           2       1.00      0.74      0.85        23\n",
      "           3       0.97      0.82      0.89        38\n",
      "           4       1.00      0.80      0.89        35\n",
      "           5       0.51      0.77      0.61        30\n",
      "           6       0.62      0.78      0.69        32\n",
      "           7       0.75      0.73      0.74        37\n",
      "           8       0.95      0.76      0.84        25\n",
      "\n",
      "    accuracy                           0.79       240\n",
      "   macro avg       0.83      0.79      0.80       240\n",
      "weighted avg       0.83      0.79      0.80       240\n",
      "\n",
      "[[0.4069884121417999, 0.8683333396911621], 'training accuracy fold #2']\n",
      "[[0.5029026865959167, 0.8083333373069763], 'testing accuracy fold #2']\n",
      "[[12  0  0  0  1  1  0  0]\n",
      " [ 1 29  0  1  1  1  0  2]\n",
      " [ 0  0 26  0  0  2  2  3]\n",
      " [ 0  0  0 23  3  0  2  1]\n",
      " [ 0  0  0  2 27  0  1  0]\n",
      " [ 0  0  0  3  5 16  0  1]\n",
      " [ 0  0  0  2  2  0 29  2]\n",
      " [ 0  0  0  1  4  1  1 32]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.92      0.86      0.89        14\n",
      "           2       1.00      0.83      0.91        35\n",
      "           3       1.00      0.79      0.88        33\n",
      "           4       0.72      0.79      0.75        29\n",
      "           5       0.63      0.90      0.74        30\n",
      "           6       0.76      0.64      0.70        25\n",
      "           7       0.83      0.83      0.83        35\n",
      "           8       0.78      0.82      0.80        39\n",
      "\n",
      "    accuracy                           0.81       240\n",
      "   macro avg       0.83      0.81      0.81       240\n",
      "weighted avg       0.83      0.81      0.81       240\n",
      "\n",
      "[[0.3891790211200714, 0.8791666626930237], 'training accuracy fold #3']\n",
      "[[0.5939260125160217, 0.7749999761581421], 'testing accuracy fold #3']\n",
      "[[ 8  2  0  0  2  0  0  0]\n",
      " [ 2 21  2  0  3  1  0  0]\n",
      " [ 0  0 31  0  3  1  0  1]\n",
      " [ 0  3  2 27  5  3  0  3]\n",
      " [ 0  2  2  0 34  0  0  1]\n",
      " [ 0  0  0  0  6 21  0  2]\n",
      " [ 0  0  0  0  4  0 15  0]\n",
      " [ 0  0  0  0  3  1  0 29]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.67      0.73        12\n",
      "           2       0.75      0.72      0.74        29\n",
      "           3       0.84      0.86      0.85        36\n",
      "           4       1.00      0.63      0.77        43\n",
      "           5       0.57      0.87      0.69        39\n",
      "           6       0.78      0.72      0.75        29\n",
      "           7       1.00      0.79      0.88        19\n",
      "           8       0.81      0.88      0.84        33\n",
      "\n",
      "    accuracy                           0.78       240\n",
      "   macro avg       0.82      0.77      0.78       240\n",
      "weighted avg       0.81      0.78      0.78       240\n",
      "\n",
      "[[0.35053306818008423, 0.8741666674613953], 'training accuracy fold #4']\n",
      "[[0.44808465242385864, 0.8208333253860474], 'testing accuracy fold #4']\n",
      "[[11  0  0  0  1  1  0  1]\n",
      " [ 4 38  1  0  3  0  0  0]\n",
      " [ 0  2 16  0  1  1  1  0]\n",
      " [ 0  0  0 18  2  1  0  3]\n",
      " [ 0  0  3  0 18  2  4  1]\n",
      " [ 0  0  0  1  3 32  0  0]\n",
      " [ 0  0  0  2  3  0 34  0]\n",
      " [ 0  0  0  0  1  1  0 30]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.79      0.76        14\n",
      "           2       0.95      0.83      0.88        46\n",
      "           3       0.80      0.76      0.78        21\n",
      "           4       0.86      0.75      0.80        24\n",
      "           5       0.56      0.64      0.60        28\n",
      "           6       0.84      0.89      0.86        36\n",
      "           7       0.87      0.87      0.87        39\n",
      "           8       0.86      0.94      0.90        32\n",
      "\n",
      "    accuracy                           0.82       240\n",
      "   macro avg       0.81      0.81      0.81       240\n",
      "weighted avg       0.83      0.82      0.82       240\n",
      "\n",
      "[[0.37070733308792114, 0.8733333349227905], 'training accuracy fold #5']\n",
      "[[0.5455397367477417, 0.7875000238418579], 'testing accuracy fold #5']\n",
      "[[15  1  0  1  1  0  0  1]\n",
      " [ 0 18  0  1  0  1  0  1]\n",
      " [ 0  0 26  0  3  2  0  1]\n",
      " [ 0  0  0 23  4  0  0  4]\n",
      " [ 0  0  0  0 30  1  0  3]\n",
      " [ 0  2  1  4  1 31  1  2]\n",
      " [ 0  0  0  4  4  0 24  0]\n",
      " [ 0  1  0  3  2  1  0 22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.79      0.88        19\n",
      "           2       0.82      0.86      0.84        21\n",
      "           3       0.96      0.81      0.88        32\n",
      "           4       0.64      0.74      0.69        31\n",
      "           5       0.67      0.88      0.76        34\n",
      "           6       0.86      0.74      0.79        42\n",
      "           7       0.96      0.75      0.84        32\n",
      "           8       0.65      0.76      0.70        29\n",
      "\n",
      "    accuracy                           0.79       240\n",
      "   macro avg       0.82      0.79      0.80       240\n",
      "weighted avg       0.81      0.79      0.79       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#ravdess 30 softmax\n",
    "import pickle\n",
    "with (open('pickle_files/ravdess_30_softmax.pckl', \"rb\")) as openfile:\n",
    "    while True:\n",
    "        try:\n",
    "            print(pickle.load(openfile))\n",
    "        except EOFError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c69e3cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
