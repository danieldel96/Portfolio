{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dirty-cradle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functional API fusion model\n",
    "import keras\n",
    "import tensorflow\n",
    "#tensorflow.debugging.set_log_device_placement(True)\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import Conv3D\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers import Input\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import datetime\n",
    "from sklearn.model_selection import KFold\n",
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "import sys\n",
    "np.set_printoptions(threshold=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d974e71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    }
   ],
   "source": [
    "gpus = tensorflow.config.list_physical_devices('GPU')\n",
    "\n",
    "\n",
    "strategy = tensorflow.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])#devices=[\"/gpu:0\", \"/gpu:1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "amended-malawi",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 80 128 128]\n",
      "[  1440 110544]\n",
      "[1440]\n"
     ]
    }
   ],
   "source": [
    "load = np.load('data/RAVDESS_all.npz',allow_pickle=True)\n",
    "audio = load['audio']\n",
    "video = load['video']\n",
    "labels = load['labels']\n",
    "n_splits = 6\n",
    "print(np.array(video[4].shape))\n",
    "print(np.array(audio.shape))\n",
    "print(np.array(labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "direct-breath",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1440, 80, 128, 128)\n",
      "(1440, 16, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "#video pre-process\n",
    "fraction = 5\n",
    "frames = int(80/fraction) #115\n",
    "shape = (128,128,frames,1)\n",
    "\n",
    "print(video.shape)\n",
    "reshape_videos = []\n",
    "\n",
    "for i in video:\n",
    "    single_video = []\n",
    "    for j in range( i.shape[0] ): #HEREi.shape[0]\n",
    "        if(  j % fraction == 0 ):\n",
    "            single_video.append( i[j] )\n",
    "    reshape_videos.append( single_video )\n",
    "\n",
    "video = np.array(reshape_videos)\n",
    "del reshape_videos\n",
    "\n",
    "print(video.shape)\n",
    "\n",
    "video_input = (128, 128, frames, 1)\n",
    "video_shape = (video.shape[0], 128, 128, frames, 1)\n",
    "video = np.reshape(video, video_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "broadband-financing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#audio pre-process\n",
    "num_rows = 110544 #84672 \n",
    "num_columns = 1\n",
    "num_channels = 1\n",
    "\n",
    "audio_input = (num_rows, num_columns)\n",
    "audio_shape = (audio.shape[0], num_rows, num_columns)\n",
    "audio = np.reshape(audio, audio_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "unable-marina",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Audio Network\n",
    "def audio_cnn_1d(input_):\n",
    "    #Layer 1\n",
    "    conv1d = Conv1D(padding='same', filters=25, kernel_size=64, strides = 8, input_shape=audio_input)(input_)\n",
    "    relu = LeakyReLU(alpha=0.2)(conv1d)\n",
    "    \n",
    "    #Layer 2\n",
    "    conv1d = Conv1D(padding='same', filters=25, kernel_size=128, strides = 8)(relu)\n",
    "    batch = BatchNormalization()(conv1d)\n",
    "    relu = LeakyReLU(alpha=0.2)(batch)\n",
    "    \n",
    "    #Layer 3\n",
    "    conv1d = Conv1D(padding='same', filters=25, kernel_size=256, strides = 8)(relu)\n",
    "    batch = BatchNormalization()(conv1d)\n",
    "    relu = LeakyReLU(alpha=0.2)(batch)\n",
    "    \n",
    "    #Layer 4\n",
    "    conv1d = Conv1D(padding='same', filters=25, kernel_size=512, strides = 4)(relu)\n",
    "    batch = BatchNormalization()(conv1d)\n",
    "    relu = LeakyReLU(alpha=0.2)(batch)\n",
    "    \n",
    "    #Layer 5\n",
    "    conv1d = Conv1D(padding='same', filters=25, kernel_size=1024, strides = 4)(relu)\n",
    "    batch = BatchNormalization()(conv1d)\n",
    "    relu = LeakyReLU(alpha=0.2)(relu)\n",
    "    \n",
    "    #layer 6\n",
    "    output = Flatten()(relu)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "extreme-skirt",
   "metadata": {},
   "outputs": [],
   "source": [
    "#video neural network\n",
    "def video_cnn_3d(input_):\n",
    "    #layer 1\n",
    "    conv3d = Conv3D(64, kernel_size=(3,3,3), strides=(2,2,1), input_shape=video_input)(input_)\n",
    "    relu = LeakyReLU(alpha=0.2)(conv3d)\n",
    "    \n",
    "    #layer 2\n",
    "    conv3d = Conv3D(128, kernel_size=(3,3,3), strides=(2,2,1), padding='SAME')(relu)\n",
    "    batch = BatchNormalization()(conv3d)\n",
    "    relu = LeakyReLU(alpha=0.2)(batch)\n",
    "    \n",
    "    #layer 3\n",
    "    conv3d = Conv3D(256, kernel_size=(3,3,3), strides=(2,2,1), padding='SAME')(relu)\n",
    "    batch = BatchNormalization()(conv3d)\n",
    "    relu = LeakyReLU(alpha=0.2)(batch)\n",
    "\n",
    "    #layer 4\n",
    "    conv3d = Conv3D(512, kernel_size=(3,3,3), strides=(2,2,2), padding='SAME')(relu)\n",
    "    batch = BatchNormalization()(conv3d)\n",
    "    relu = LeakyReLU(alpha=0.2)(batch)\n",
    "\n",
    "    #layer 5\n",
    "    conv3d = Conv3D(1024, kernel_size=(3,3,3), strides=(2,2,2), padding='SAME')(relu)\n",
    "    batch = BatchNormalization()(conv3d)\n",
    "    relu = LeakyReLU(alpha=0.2)(batch)\n",
    "\n",
    "    #layer 6\n",
    "    conv3d = Conv3D(2048, kernel_size=(3,3,3), strides=(2,2,2), padding='SAME')(relu)\n",
    "    batch = BatchNormalization()(conv3d)\n",
    "    relu = LeakyReLU(alpha=0.2)(batch)\n",
    "\n",
    "    #layer 7\n",
    "    output = Flatten()(relu)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "regional-force",
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels = labels - 1\n",
    "labels = to_categorical(labels)\n",
    "target_names = ['neutral', 'calm', 'happy', 'sad', 'angry', 'fearful', 'disgust', 'surprised']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "relative-quantum",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=6, random_state=42, shuffle=True)\n",
      "(1440, 110544, 1)\n",
      "(1440, 9)\n",
      "Beginning fold #0...\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/duff/b/homes/RUIZLAB/danieldel/projects/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "INFO:tensorflow:batch_all_reduce: 40 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 40 all-reduces with algorithm = nccl, num_packs = 1\n",
      "34/34 [==============================] - 23s 399ms/step - loss: 2.2500 - accuracy: 0.3890 - val_loss: 2.1680 - val_accuracy: 0.1600\n",
      "Epoch 2/30\n",
      "34/34 [==============================] - 10s 285ms/step - loss: 0.3205 - accuracy: 0.9100 - val_loss: 2.2124 - val_accuracy: 0.1300\n",
      "Epoch 3/30\n",
      "34/34 [==============================] - 10s 289ms/step - loss: 0.1129 - accuracy: 0.9730 - val_loss: 2.2548 - val_accuracy: 0.1650\n",
      "Epoch 4/30\n",
      "34/34 [==============================] - 10s 290ms/step - loss: 0.0525 - accuracy: 0.9920 - val_loss: 2.3184 - val_accuracy: 0.1800\n",
      "Epoch 5/30\n",
      "34/34 [==============================] - 10s 285ms/step - loss: 0.0307 - accuracy: 0.9980 - val_loss: 2.4182 - val_accuracy: 0.1850\n",
      "INFO:tensorflow:Assets written to: models/ravdess_30_softmax/assets\n",
      "Epoch 6/30\n",
      "34/34 [==============================] - 10s 287ms/step - loss: 0.0303 - accuracy: 0.9960 - val_loss: 2.5481 - val_accuracy: 0.1400\n",
      "Epoch 7/30\n",
      "34/34 [==============================] - 10s 292ms/step - loss: 0.0380 - accuracy: 0.9960 - val_loss: 2.8264 - val_accuracy: 0.1650\n",
      "Epoch 8/30\n",
      "34/34 [==============================] - 10s 283ms/step - loss: 0.0177 - accuracy: 0.9980 - val_loss: 3.3606 - val_accuracy: 0.1500\n",
      "Epoch 9/30\n",
      "34/34 [==============================] - 10s 282ms/step - loss: 0.0137 - accuracy: 0.9990 - val_loss: 3.4282 - val_accuracy: 0.1400\n",
      "Epoch 10/30\n",
      " 8/34 [======>.......................] - ETA: 6s - loss: 0.0120 - accuracy: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-c750806f5869>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         twin_net.fit([a_train,v_train], l_train,\n\u001b[0m\u001b[1;32m     65\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1187\u001b[0m                 _r=1):\n\u001b[1;32m   1188\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/projects/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#k-Fold training, set for 6 splits\n",
    "\n",
    "n = 0 #current fold\n",
    "\n",
    "epochs = 30\n",
    "function = 'softmax'\n",
    "name = 'ravdess_' + str(epochs) + '_' + function \n",
    "pickle_file = 'pickle_files/' + name + '.pckl'\n",
    "\n",
    "training_score = []\n",
    "testing_score = []\n",
    "\n",
    "f = open(pickle_file, 'wb') #file for saving information/data about each fold\n",
    "\n",
    "\n",
    "kf = KFold(n_splits,shuffle=True,random_state=42)\n",
    "kf.get_n_splits(audio)\n",
    "\n",
    "print(kf)\n",
    "\n",
    "print(audio.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "for train_index, test_index in kf.split(audio):\n",
    "    print('Beginning fold #' + str(n) + '...')\n",
    "    #print(train_index)\n",
    "    #print(test_index)\n",
    "    a_train, a_test = audio[train_index], audio[test_index]\n",
    "    v_train, v_test = video[train_index], video[test_index]\n",
    "    l_train, l_test = labels[train_index], labels[test_index]\n",
    "    \n",
    "    \n",
    "    with strategy.scope():\n",
    "        #fusion layer\n",
    "        aud = Input(audio_input)\n",
    "        vid = Input(video_input)\n",
    "\n",
    "        audio_tensor = audio_cnn_1d(aud)\n",
    "\n",
    "        video_tensor = video_cnn_3d(vid)\n",
    "\n",
    "        fusion = Concatenate()([audio_tensor, video_tensor]) #combining tensors\n",
    "        batch = BatchNormalization()(fusion)\n",
    "        prediction = Dense(9,activation=function)(batch) #softmax\n",
    "        twin_net = Model(inputs=[aud,vid], outputs=prediction)\n",
    "\n",
    "        #Training\n",
    "\n",
    "        checkpoint_filepath = 'models/' + name\n",
    "        model_checkpoint_callback = ModelCheckpoint(\n",
    "            filepath=checkpoint_filepath,\n",
    "            period=5\n",
    "            )\n",
    "        log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + checkpoint_filepath\n",
    "        tensorboard_callback = tensorflow.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "        twin_net.compile(loss='categorical_crossentropy', #categorical_crossentropy\n",
    "                optimizer=optimizers.Adam(lr=0.00001), \n",
    "                         metrics=['accuracy'])\n",
    "\n",
    "        #twin_net.summary()\n",
    "\n",
    "\n",
    "        twin_net.fit([a_train,v_train], l_train,\n",
    "                batch_size=30,\n",
    "                epochs=epochs,\n",
    "                verbose=1,\n",
    "                validation_split=0.166,\n",
    "                callbacks=[model_checkpoint_callback,\n",
    "                tensorboard_callback])\n",
    "        \n",
    "        score = twin_net.evaluate([a_train, v_train], l_train, verbose=0)\n",
    "        pickle.dump([score, 'training accuracy fold #' + str(n)], f)\n",
    "        training_score.append(score)\n",
    "\n",
    "        score = twin_net.evaluate([a_test, v_test], l_test, verbose=0)\n",
    "        pickle.dump([score, 'testing accuracy fold #' + str(n)], f)\n",
    "        testing_score.append(score)\n",
    "\n",
    "        Y_pred = twin_net.predict([a_test, v_test])\n",
    "        y_pred = np.argmax(Y_pred, axis=1)\n",
    "        labels_ = np.argmax(l_test, axis=1)\n",
    "        pickle.dump(confusion_matrix(labels_, y_pred), f)\n",
    "        pickle.dump(classification_report(labels_, y_pred), f)\n",
    "        \n",
    "        n+=1\n",
    "        \n",
    "f.close()\n",
    "np.savez('data/'+name,x=training_score,y=testing_score)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a94c0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.12794378 0.87083334]\n",
      " [0.25130668 0.87166667]\n",
      " [0.13913345 0.87083334]\n",
      " [0.11137921 0.8775    ]\n",
      " [0.12883507 0.86916667]\n",
      " [0.13996606 0.88249999]] [[0.17372778 0.8125    ]\n",
      " [0.34023979 0.77083331]\n",
      " [0.17262281 0.82499999]\n",
      " [0.21816924 0.77916664]\n",
      " [0.14409503 0.84166664]\n",
      " [0.20448479 0.81666666]]\n",
      "[[0.12794378399848938, 0.8708333373069763], 'training accuracy fold #0']\n",
      "[[0.17372778058052063, 0.8125], 'testing accuracy fold #0']\n",
      "[[15  0  0  0  1  1  0  0]\n",
      " [ 0 34  0  0  1  2  0  1]\n",
      " [ 0  3 23  0  0  2  0  4]\n",
      " [ 2  0  1 19  5  3  0  0]\n",
      " [ 0  2  0  0 29  0  0  0]\n",
      " [ 0  2  0  0  2 22  2  0]\n",
      " [ 0  1  0  1  2  1 25  0]\n",
      " [ 0  0  3  0  0  1  2 28]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.88      0.88        17\n",
      "           2       0.81      0.89      0.85        38\n",
      "           3       0.85      0.72      0.78        32\n",
      "           4       0.95      0.63      0.76        30\n",
      "           5       0.72      0.94      0.82        31\n",
      "           6       0.69      0.79      0.73        28\n",
      "           7       0.86      0.83      0.85        30\n",
      "           8       0.85      0.82      0.84        34\n",
      "\n",
      "    accuracy                           0.81       240\n",
      "   macro avg       0.83      0.81      0.81       240\n",
      "weighted avg       0.82      0.81      0.81       240\n",
      "\n",
      "[[0.2513066828250885, 0.871666669845581], 'training accuracy fold #1']\n",
      "[[0.3402397930622101, 0.7708333134651184], 'testing accuracy fold #1']\n",
      "[[19  0  0  0  1  0  0  0]\n",
      " [ 0 21  0  0  0  2  0  0]\n",
      " [ 0  6 28  0  3  1  0  0]\n",
      " [ 0  4  0 24  4  3  0  0]\n",
      " [ 0  3  0  0 23  3  1  0]\n",
      " [ 0  1  0  0  2 25  3  1]\n",
      " [ 0  5  0  1  2  3 26  0]\n",
      " [ 0  2  0  1  3  0  0 19]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.95      0.97        20\n",
      "           2       0.50      0.91      0.65        23\n",
      "           3       1.00      0.74      0.85        38\n",
      "           4       0.92      0.69      0.79        35\n",
      "           5       0.61      0.77      0.68        30\n",
      "           6       0.68      0.78      0.72        32\n",
      "           7       0.87      0.70      0.78        37\n",
      "           8       0.95      0.76      0.84        25\n",
      "\n",
      "    accuracy                           0.77       240\n",
      "   macro avg       0.82      0.79      0.78       240\n",
      "weighted avg       0.82      0.77      0.78       240\n",
      "\n",
      "[[0.13913345336914062, 0.8708333373069763], 'training accuracy fold #2']\n",
      "[[0.17262281477451324, 0.824999988079071], 'testing accuracy fold #2']\n",
      "[[12  0  0  0  1  1  0  0]\n",
      " [ 0 30  3  0  0  2  0  0]\n",
      " [ 0  0 28  0  0  5  0  0]\n",
      " [ 0  0  0 23  3  0  2  1]\n",
      " [ 0  0  0  4 26  0  0  0]\n",
      " [ 0  0  0  1  4 16  4  0]\n",
      " [ 0  0  1  0  1  1 30  2]\n",
      " [ 0  0  0  0  3  3  0 33]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.86      0.92        14\n",
      "           2       1.00      0.86      0.92        35\n",
      "           3       0.88      0.85      0.86        33\n",
      "           4       0.82      0.79      0.81        29\n",
      "           5       0.68      0.87      0.76        30\n",
      "           6       0.57      0.64      0.60        25\n",
      "           7       0.83      0.86      0.85        35\n",
      "           8       0.92      0.85      0.88        39\n",
      "\n",
      "    accuracy                           0.82       240\n",
      "   macro avg       0.84      0.82      0.83       240\n",
      "weighted avg       0.84      0.82      0.83       240\n",
      "\n",
      "[[0.1113792136311531, 0.8774999976158142], 'training accuracy fold #3']\n",
      "[[0.21816924214363098, 0.7791666388511658], 'testing accuracy fold #3']\n",
      "[[ 8  3  0  0  1  0  0  0]\n",
      " [ 2 22  4  0  0  1  0  0]\n",
      " [ 0  0 32  0  2  1  1  0]\n",
      " [ 0  2  2 25  5  4  2  3]\n",
      " [ 0  3  2  0 34  0  0  0]\n",
      " [ 0  0  0  0  5 22  1  1]\n",
      " [ 0  0  0  1  3  0 15  0]\n",
      " [ 0  0  0  1  2  1  0 29]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.67      0.73        12\n",
      "           2       0.73      0.76      0.75        29\n",
      "           3       0.80      0.89      0.84        36\n",
      "           4       0.93      0.58      0.71        43\n",
      "           5       0.65      0.87      0.75        39\n",
      "           6       0.76      0.76      0.76        29\n",
      "           7       0.79      0.79      0.79        19\n",
      "           8       0.88      0.88      0.88        33\n",
      "\n",
      "    accuracy                           0.78       240\n",
      "   macro avg       0.79      0.77      0.78       240\n",
      "weighted avg       0.80      0.78      0.78       240\n",
      "\n",
      "[[0.128835067152977, 0.8691666722297668], 'training accuracy fold #4']\n",
      "[[0.1440950334072113, 0.8416666388511658], 'testing accuracy fold #4']\n",
      "[[11  0  0  0  1  1  0  1]\n",
      " [ 4 38  0  2  1  1  0  0]\n",
      " [ 0  2 16  0  1  1  1  0]\n",
      " [ 0  0  0 20  2  1  1  0]\n",
      " [ 0  0  0  0 24  2  2  0]\n",
      " [ 0  0  0  0  3 33  0  0]\n",
      " [ 0  2  0  2  3  2 30  0]\n",
      " [ 0  0  0  0  1  1  0 30]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.79      0.76        14\n",
      "           2       0.90      0.83      0.86        46\n",
      "           3       1.00      0.76      0.86        21\n",
      "           4       0.83      0.83      0.83        24\n",
      "           5       0.67      0.86      0.75        28\n",
      "           6       0.79      0.92      0.85        36\n",
      "           7       0.88      0.77      0.82        39\n",
      "           8       0.97      0.94      0.95        32\n",
      "\n",
      "    accuracy                           0.84       240\n",
      "   macro avg       0.85      0.84      0.84       240\n",
      "weighted avg       0.86      0.84      0.84       240\n",
      "\n",
      "[[0.13996605575084686, 0.8824999928474426], 'training accuracy fold #5']\n",
      "[[0.20448479056358337, 0.8166666626930237], 'testing accuracy fold #5']\n",
      "[[15  1  0  0  1  1  1  0]\n",
      " [ 0 18  0  1  0  1  0  1]\n",
      " [ 0  0 27  0  3  1  0  1]\n",
      " [ 0  0  2 23  2  0  0  4]\n",
      " [ 0  0  0  0 31  1  0  2]\n",
      " [ 0  2  1  2  1 33  1  2]\n",
      " [ 0  1  1  0  2  0 26  2]\n",
      " [ 0  0  0  2  2  2  0 23]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.79      0.88        19\n",
      "           2       0.82      0.86      0.84        21\n",
      "           3       0.87      0.84      0.86        32\n",
      "           4       0.82      0.74      0.78        31\n",
      "           5       0.74      0.91      0.82        34\n",
      "           6       0.85      0.79      0.81        42\n",
      "           7       0.93      0.81      0.87        32\n",
      "           8       0.66      0.79      0.72        29\n",
      "\n",
      "    accuracy                           0.82       240\n",
      "   macro avg       0.84      0.82      0.82       240\n",
      "weighted avg       0.83      0.82      0.82       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "load = np.load('data/'+name+'.npz')\n",
    "training_score = load['x']\n",
    "testing_score = load['y']\n",
    "\n",
    "print(training_score,testing_score)\n",
    "\n",
    "f.close()\n",
    "\n",
    "with (open(pickle_file, \"rb\")) as openfile:\n",
    "    while True:\n",
    "        try:\n",
    "            print(pickle.load(openfile))\n",
    "        except EOFError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0cd927",
   "metadata": {},
   "source": [
    "INFO:tensorflow:Assets written to: models/ravdess_30_sigmoid/assets\n",
    "[[0.3629540205001831, 0.8600000143051147], 'training accuracy fold #0']\n",
    "[[0.5187535285949707, 0.7833333611488342], 'testing accuracy fold #0']\n",
    "[[15  0  0  1  0  1  0  0]\n",
    " [ 2 32  0  2  0  2  0  0]\n",
    " [ 0  0 25  2  0  2  3  0]\n",
    " [ 2  0  0 19  5  3  1  0]\n",
    " [ 0  1  0  2 27  1  0  0]\n",
    " [ 2  2  0  0  2 20  2  0]\n",
    " [ 0  0  0  0  2  3 25  0]\n",
    " [ 0  0  4  2  0  1  2 25]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           1       0.71      0.88      0.79        17\n",
    "           2       0.91      0.84      0.88        38\n",
    "           3       0.86      0.78      0.82        32\n",
    "           4       0.68      0.63      0.66        30\n",
    "           5       0.75      0.87      0.81        31\n",
    "           6       0.61      0.71      0.66        28\n",
    "           7       0.76      0.83      0.79        30\n",
    "           8       1.00      0.74      0.85        34\n",
    "\n",
    "    accuracy                           0.78       240\n",
    "   macro avg       0.79      0.79      0.78       240\n",
    "weighted avg       0.80      0.78      0.79       240\n",
    "\n",
    "[[0.3796142041683197, 0.8700000047683716], 'training accuracy fold #1']\n",
    "[[0.5539751648902893, 0.7708333134651184], 'testing accuracy fold #1']\n",
    "[[19  0  0  0  1  0  0  0]\n",
    " [ 0 20  0  0  0  3  0  0]\n",
    " [ 0  1 29  0  4  1  1  2]\n",
    " [ 2  0  0 26  2  3  0  2]\n",
    " [ 0  1  0  0 24  5  0  0]\n",
    " [ 1  0  0  1  3 23  3  1]\n",
    " [ 0  0  0  0  5  5 27  0]\n",
    " [ 0  1  0  0  3  2  2 17]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           1       0.86      0.95      0.90        20\n",
    "           2       0.87      0.87      0.87        23\n",
    "           3       1.00      0.76      0.87        38\n",
    "           4       0.96      0.74      0.84        35\n",
    "           5       0.57      0.80      0.67        30\n",
    "           6       0.55      0.72      0.62        32\n",
    "           7       0.82      0.73      0.77        37\n",
    "           8       0.77      0.68      0.72        25\n",
    "\n",
    "    accuracy                           0.77       240\n",
    "   macro avg       0.80      0.78      0.78       240\n",
    "weighted avg       0.81      0.77      0.78       240\n",
    "\n",
    "[[0.37501320242881775, 0.8641666769981384], 'training accuracy fold #2']\n",
    "[[0.47459012269973755, 0.7916666865348816], 'testing accuracy fold #2']\n",
    "[[12  0  0  0  1  1  0  0]\n",
    " [ 2 28  2  0  0  2  0  1]\n",
    " [ 2  0 26  0  2  2  0  1]\n",
    " [ 0  0  0 23  3  0  2  1]\n",
    " [ 0  2  0  3 25  0  0  0]\n",
    " [ 0  0  0  2  4 17  2  0]\n",
    " [ 0  0  0  2  2  2 27  2]\n",
    " [ 0  0  0  1  3  2  1 32]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           1       0.75      0.86      0.80        14\n",
    "           2       0.93      0.80      0.86        35\n",
    "           3       0.93      0.79      0.85        33\n",
    "           4       0.74      0.79      0.77        29\n",
    "           5       0.62      0.83      0.71        30\n",
    "           6       0.65      0.68      0.67        25\n",
    "           7       0.84      0.77      0.81        35\n",
    "           8       0.86      0.82      0.84        39\n",
    "\n",
    "    accuracy                           0.79       240\n",
    "   macro avg       0.79      0.79      0.79       240\n",
    "weighted avg       0.81      0.79      0.80       240\n",
    "\n",
    "[[0.3411281406879425, 0.8633333444595337], 'training accuracy fold #3']\n",
    "[[0.5509750247001648, 0.7791666388511658], 'testing accuracy fold #3']\n",
    "[[ 8  2  0  1  0  0  0  1]\n",
    " [ 0 23  0  4  0  1  0  1]\n",
    " [ 0  0 29  1  3  1  0  2]\n",
    " [ 0  2  0 30  5  4  0  2]\n",
    " [ 0  1  2  1 32  3  0  0]\n",
    " [ 0  1  0  0  4 24  0  0]\n",
    " [ 0  0  0  2  2  0 15  0]\n",
    " [ 0  3  0  1  2  0  1 26]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           1       1.00      0.67      0.80        12\n",
    "           2       0.72      0.79      0.75        29\n",
    "           3       0.94      0.81      0.87        36\n",
    "           4       0.75      0.70      0.72        43\n",
    "           5       0.67      0.82      0.74        39\n",
    "           6       0.73      0.83      0.77        29\n",
    "           7       0.94      0.79      0.86        19\n",
    "           8       0.81      0.79      0.80        33\n",
    "\n",
    "    accuracy                           0.78       240\n",
    "   macro avg       0.82      0.77      0.79       240\n",
    "weighted avg       0.79      0.78      0.78       240\n",
    "\n",
    "[[0.36666935682296753, 0.8608333468437195], 'training accuracy fold #4']\n",
    "[[0.4919424057006836, 0.800000011920929], 'testing accuracy fold #4']\n",
    "[[11  1  0  1  1  0  0  0]\n",
    " [ 4 34  0  2  5  1  0  0]\n",
    " [ 0  2 15  2  1  1  0  0]\n",
    " [ 0  0  0 20  2  2  0  0]\n",
    " [ 1  0  0  2 20  5  0  0]\n",
    " [ 0  0  0  0  2 34  0  0]\n",
    " [ 0  0  0  4  3  1 31  0]\n",
    " [ 0  0  0  0  2  1  2 27]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           1       0.69      0.79      0.73        14\n",
    "           2       0.92      0.74      0.82        46\n",
    "           3       1.00      0.71      0.83        21\n",
    "           4       0.65      0.83      0.73        24\n",
    "           5       0.56      0.71      0.63        28\n",
    "           6       0.76      0.94      0.84        36\n",
    "           7       0.94      0.79      0.86        39\n",
    "           8       1.00      0.84      0.92        32\n",
    "\n",
    "    accuracy                           0.80       240\n",
    "   macro avg       0.81      0.80      0.79       240\n",
    "weighted avg       0.83      0.80      0.81       240\n",
    "\n",
    "[[0.3825329542160034, 0.8700000047683716], 'training accuracy fold #5']\n",
    "[[0.580239474773407, 0.7916666865348816], 'testing accuracy fold #5']\n",
    "[[15  0  0  1  2  1  0  0]\n",
    " [ 0 18  0  0  1  2  0  0]\n",
    " [ 0  0 26  0  4  2  0  0]\n",
    " [ 0  0  0 23  6  0  0  2]\n",
    " [ 0  0  0  0 33  1  0  0]\n",
    " [ 0  3  0  2  5 32  0  0]\n",
    " [ 1  0  0  2  2  4 22  1]\n",
    " [ 0  0  0  0  6  2  0 21]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           1       0.94      0.79      0.86        19\n",
    "           2       0.86      0.86      0.86        21\n",
    "           3       1.00      0.81      0.90        32\n",
    "           4       0.82      0.74      0.78        31\n",
    "           5       0.56      0.97      0.71        34\n",
    "           6       0.73      0.76      0.74        42\n",
    "           7       1.00      0.69      0.81        32\n",
    "           8       0.88      0.72      0.79        29\n",
    "\n",
    "    accuracy                           0.79       240\n",
    "   macro avg       0.85      0.79      0.81       240\n",
    "weighted avg       0.83      0.79      0.80       240"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c3b692",
   "metadata": {},
   "outputs": [],
   "source": [
    "with (open(pickle_file, \"rb\")) as openfile:\n",
    "    while True:\n",
    "        try:\n",
    "            print(pickle.load(openfile))\n",
    "        except EOFError:\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patient-western",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    #test sigmoid\n",
    "    model = load_model('models/ravdess_softmax_extended')\n",
    "\n",
    "\n",
    "    score = model.evaluate([a_train, v_train], l_train, verbose=0)\n",
    "    print(\"Training Accuracy: \", score)\n",
    "\n",
    "    score = model.evaluate([a_test, v_test], l_test, verbose=0)\n",
    "    print(\"Testing Accuracy: \", score)\n",
    "\n",
    "\n",
    "    Y_pred = model.predict([a_test, v_test])\n",
    "    y_pred = np.argmax(Y_pred, axis=1)\n",
    "    labels = np.argmax(l_test, axis=1)\n",
    "    print('Confusion_Matrix')\n",
    "    print(confusion_matrix(labels, y_pred))\n",
    "\n",
    "    print('Classification Report')\n",
    "    print(classification_report(labels, y_pred, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d3424e",
   "metadata": {},
   "source": [
    "300 epoch softmax\n",
    "Training Accuracy:  [0.3390514552593231, 0.9666666388511658]\n",
    "Testing Accuracy:  [2.35433292388916, 0.7958333492279053]\n",
    "Confusion_Matrix\n",
    "[[17  0  0  0  0  0  0  0]\n",
    " [ 3 31  0  0  2  0  1  1]\n",
    " [ 0  0 23  4  0  1  2  2]\n",
    " [ 2  0  2 22  2  0  1  1]\n",
    " [ 0  0  0  3 27  0  0  1]\n",
    " [ 3  2  0  0  2 18  3  0]\n",
    " [ 0  0  0  1  0  2 27  0]\n",
    " [ 0  1  3  1  0  0  3 26]]\n",
    "Classification Report\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "     neutral       0.68      1.00      0.81        17\n",
    "        calm       0.91      0.82      0.86        38\n",
    "       happy       0.82      0.72      0.77        32\n",
    "         sad       0.71      0.73      0.72        30\n",
    "       angry       0.82      0.87      0.84        31\n",
    "     fearful       0.86      0.64      0.73        28\n",
    "     disgust       0.73      0.90      0.81        30\n",
    "   surprised       0.84      0.76      0.80        34\n",
    "\n",
    "    accuracy                           0.80       240\n",
    "   macro avg       0.80      0.81      0.79       240\n",
    "weighted avg       0.81      0.80      0.79       240\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa61b8cb",
   "metadata": {},
   "source": [
    "Training Accuracy:  [0.3390514552593231, 0.9666666388511658]\n",
    "Testing Accuracy:  [2.35433292388916, 0.7958333492279053]\n",
    "Confusion_Matrix\n",
    "[[17  0  0  0  0  0  0  0]\n",
    " [ 3 31  0  0  2  0  1  1]\n",
    " [ 0  0 23  4  0  1  2  2]\n",
    " [ 2  0  2 22  2  0  1  1]\n",
    " [ 0  0  0  3 27  0  0  1]\n",
    " [ 3  2  0  0  2 18  3  0]\n",
    " [ 0  0  0  1  0  2 27  0]\n",
    " [ 0  1  3  1  0  0  3 26]]\n",
    "Classification Report\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "     neutral       0.68      1.00      0.81        17\n",
    "        calm       0.91      0.82      0.86        38\n",
    "       happy       0.82      0.72      0.77        32\n",
    "         sad       0.71      0.73      0.72        30\n",
    "       angry       0.82      0.87      0.84        31\n",
    "     fearful       0.86      0.64      0.73        28\n",
    "     disgust       0.73      0.90      0.81        30\n",
    "   surprised       0.84      0.76      0.80        34\n",
    "\n",
    "    accuracy                           0.80       240\n",
    "   macro avg       0.80      0.81      0.79       240\n",
    "weighted avg       0.81      0.80      0.79       240"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aaae41d",
   "metadata": {},
   "source": [
    "sigmoid 300 ravdess\n",
    "Training Accuracy:  [0.019113920629024506, 0.9758333563804626]\n",
    "Testing Accuracy:  [0.13955293595790863, 0.8541666865348816]\n",
    "Confusion_Matrix\n",
    "[[17  0  0  0  0  0  0  0]\n",
    " [ 0 35  1  1  0  0  0  1]\n",
    " [ 0  0 29  0  0  0  2  1]\n",
    " [ 0  2  2 22  2  0  1  1]\n",
    " [ 0  0  0  2 27  0  1  1]\n",
    " [ 0  1  0  1  2 21  3  0]\n",
    " [ 0  0  0  1  1  2 26  0]\n",
    " [ 0  0  4  0  0  0  2 28]]\n",
    "Classification Report\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "     neutral       1.00      1.00      1.00        17\n",
    "        calm       0.92      0.92      0.92        38\n",
    "       happy       0.81      0.91      0.85        32\n",
    "         sad       0.81      0.73      0.77        30\n",
    "       angry       0.84      0.87      0.86        31\n",
    "     fearful       0.91      0.75      0.82        28\n",
    "     disgust       0.74      0.87      0.80        30\n",
    "   surprised       0.88      0.82      0.85        34\n",
    "\n",
    "    accuracy                           0.85       240\n",
    "   macro avg       0.86      0.86      0.86       240\n",
    "weighted avg       0.86      0.85      0.85       240\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41317fc",
   "metadata": {},
   "source": [
    "sigmoid\n",
    "Training Accuracy:  [0.15417054295539856, 0.9775000214576721]\n",
    "Testing Accuracy:  [0.3786163330078125, 0.824999988079071]\n",
    "Confusion_Matrix\n",
    "[[17  0  0  0  0  0  0  0]\n",
    " [ 0 35  1  0  0  1  0  1]\n",
    " [ 0  4 24  0  0  2  2  0]\n",
    " [ 2  0  2 22  2  0  1  1]\n",
    " [ 0  0  0  1 29  0  0  1]\n",
    " [ 2  0  2  0  0 20  4  0]\n",
    " [ 0  0  1  1  0  2 26  0]\n",
    " [ 0  0  5  0  0  1  3 25]]\n",
    "Classification Report\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "     neutral       0.81      1.00      0.89        17\n",
    "        calm       0.90      0.92      0.91        38\n",
    "       happy       0.69      0.75      0.72        32\n",
    "         sad       0.92      0.73      0.81        30\n",
    "       angry       0.94      0.94      0.94        31\n",
    "     fearful       0.77      0.71      0.74        28\n",
    "     disgust       0.72      0.87      0.79        30\n",
    "   surprised       0.89      0.74      0.81        34\n",
    "\n",
    "    accuracy                           0.82       240\n",
    "   macro avg       0.83      0.83      0.83       240\n",
    "weighted avg       0.83      0.82      0.82       240\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "differential-emission",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  [0.07032961398363113, 0.9758333563804626]\n",
      "Testing Accuracy:  [0.6477829217910767, 0.8166666626930237]\n",
      "Confusion_Matrix\n",
      "[[ 0  0  0  0  0  0  0  0  0]\n",
      " [ 0 15  3  0  0  0  2  0  0]\n",
      " [ 0  4 41  0  0  0  0  0  0]\n",
      " [ 0  0  2 16  0  0  2  4  2]\n",
      " [ 0  0  0  0 21  1  0  2  2]\n",
      " [ 1  0  0  0  1 23  0  2  0]\n",
      " [ 0  0  2  0  0  2 22  1  1]\n",
      " [ 0  0  1  0  0  0  3 25  0]\n",
      " [ 0  2  0  1  1  1  0  1 33]]\n"
     ]
    }
   ],
   "source": [
    "#test softmax\n",
    "model = load_model('models/twin_net_softmax')\n",
    "\n",
    "\n",
    "score = model.evaluate([a_train, v_train], l_train, verbose=0)\n",
    "print(\"Training Accuracy: \", score)\n",
    "\n",
    "score = model.evaluate([a_test, v_test], l_test, verbose=0)\n",
    "print(\"Testing Accuracy: \", score)\n",
    "\n",
    "\n",
    "Y_pred = model.predict([a_test, v_test])\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "labels = np.argmax(l_test, axis=1)\n",
    "print('Confusion_Matrix')\n",
    "print(confusion_matrix(labels, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
