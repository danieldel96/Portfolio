{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dirty-cradle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functional API fusion model\n",
    "import keras\n",
    "import tensorflow\n",
    "#tensorflow.debugging.set_log_device_placement(True)\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import Conv3D\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers import Input\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import datetime\n",
    "from sklearn.model_selection import KFold\n",
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "import sys\n",
    "np.set_printoptions(threshold=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d974e71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    }
   ],
   "source": [
    "gpus = tensorflow.config.list_physical_devices('GPU')\n",
    "\n",
    "\n",
    "strategy = tensorflow.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])#devices=[\"/gpu:0\", \"/gpu:1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "amended-malawi",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1152  115  128  128]\n",
      "[  1152 110544]\n",
      "[1152]\n"
     ]
    }
   ],
   "source": [
    "load = np.load('data/RAVDESS_basic.npz',allow_pickle=True)\n",
    "audio = load['audio']\n",
    "video = load['video']\n",
    "labels = load['labels']\n",
    "n_splits = 6\n",
    "print(np.array(video.shape))\n",
    "print(np.array(audio.shape))\n",
    "print(np.array(labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "direct-breath",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1152, 115, 128, 128)\n",
      "(1152, 23, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "#video pre-process\n",
    "fraction = 5\n",
    "frames = int(video.shape[1]/fraction) #115\n",
    "shape = (128,128,frames,1)\n",
    "\n",
    "print(video.shape)\n",
    "reshape_videos = []\n",
    "\n",
    "for i in video:\n",
    "    single_video = []\n",
    "    for j in range( i.shape[0] ): #HEREi.shape[0]\n",
    "        if(  j % fraction == 0 ):\n",
    "            single_video.append( i[j] )\n",
    "    reshape_videos.append( single_video )\n",
    "\n",
    "video = np.array(reshape_videos)\n",
    "del reshape_videos\n",
    "\n",
    "print(video.shape)\n",
    "\n",
    "video_input = (128, 128, frames, 1)\n",
    "video_shape = (video.shape[0], 128, 128, frames, 1)\n",
    "video = np.reshape(video, video_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "broadband-financing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#audio pre-process\n",
    "num_rows = 110544 #84672 \n",
    "num_columns = 1\n",
    "num_channels = 1\n",
    "\n",
    "audio_input = (num_rows, num_columns)\n",
    "audio_shape = (audio.shape[0], num_rows, num_columns)\n",
    "audio = np.reshape(audio, audio_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "unable-marina",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Audio Network\n",
    "def audio_cnn_1d(input_):\n",
    "    #Layer 1\n",
    "    conv1d = Conv1D(padding='same', filters=25, kernel_size=64, strides = 8, input_shape=audio_input)(input_)\n",
    "    relu = LeakyReLU(alpha=0.2)(conv1d)\n",
    "    \n",
    "    #Layer 2\n",
    "    conv1d = Conv1D(padding='same', filters=25, kernel_size=128, strides = 8)(relu)\n",
    "    batch = BatchNormalization()(conv1d)\n",
    "    relu = LeakyReLU(alpha=0.2)(batch)\n",
    "    \n",
    "    #Layer 3\n",
    "    conv1d = Conv1D(padding='same', filters=25, kernel_size=256, strides = 8)(relu)\n",
    "    batch = BatchNormalization()(conv1d)\n",
    "    relu = LeakyReLU(alpha=0.2)(batch)\n",
    "    \n",
    "    #Layer 4\n",
    "    conv1d = Conv1D(padding='same', filters=25, kernel_size=512, strides = 4)(relu)\n",
    "    batch = BatchNormalization()(conv1d)\n",
    "    relu = LeakyReLU(alpha=0.2)(batch)\n",
    "    \n",
    "    #Layer 5\n",
    "    conv1d = Conv1D(padding='same', filters=25, kernel_size=1024, strides = 4)(relu)\n",
    "    batch = BatchNormalization()(conv1d)\n",
    "    relu = LeakyReLU(alpha=0.2)(relu)\n",
    "    \n",
    "    #layer 6\n",
    "    output = Flatten()(relu)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "extreme-skirt",
   "metadata": {},
   "outputs": [],
   "source": [
    "#video neural network\n",
    "def video_cnn_3d(input_):\n",
    "    #layer 1\n",
    "    conv3d = Conv3D(64, kernel_size=(3,3,3), strides=(2,2,1), input_shape=video_input)(input_)\n",
    "    relu = LeakyReLU(alpha=0.2)(conv3d)\n",
    "    \n",
    "    #layer 2\n",
    "    conv3d = Conv3D(128, kernel_size=(3,3,3), strides=(2,2,1), padding='SAME')(relu)\n",
    "    batch = BatchNormalization()(conv3d)\n",
    "    relu = LeakyReLU(alpha=0.2)(batch)\n",
    "    \n",
    "    #layer 3\n",
    "    conv3d = Conv3D(256, kernel_size=(3,3,3), strides=(2,2,1), padding='SAME')(relu)\n",
    "    batch = BatchNormalization()(conv3d)\n",
    "    relu = LeakyReLU(alpha=0.2)(batch)\n",
    "\n",
    "    #layer 4\n",
    "    conv3d = Conv3D(512, kernel_size=(3,3,3), strides=(2,2,2), padding='SAME')(relu)\n",
    "    batch = BatchNormalization()(conv3d)\n",
    "    relu = LeakyReLU(alpha=0.2)(batch)\n",
    "\n",
    "    #layer 5\n",
    "    conv3d = Conv3D(1024, kernel_size=(3,3,3), strides=(2,2,2), padding='SAME')(relu)\n",
    "    batch = BatchNormalization()(conv3d)\n",
    "    relu = LeakyReLU(alpha=0.2)(batch)\n",
    "\n",
    "    #layer 6\n",
    "    conv3d = Conv3D(2048, kernel_size=(3,3,3), strides=(2,2,2), padding='SAME')(relu)\n",
    "    batch = BatchNormalization()(conv3d)\n",
    "    relu = LeakyReLU(alpha=0.2)(batch)\n",
    "\n",
    "    #layer 7\n",
    "    output = Flatten()(relu)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "regional-force",
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels = labels - 1\n",
    "labels = to_categorical(labels)\n",
    "target_names = ['neutral', 'calm', 'happy', 'sad', 'angry', 'fearful', 'disgust', 'surprised']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "relative-quantum",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=6, random_state=42, shuffle=True)\n",
      "(1152, 110544, 1)\n",
      "(1152, 6)\n",
      "Beginning fold #0...\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n",
      "27/27 [==============================] - 21s 512ms/step - loss: 2.1048 - accuracy: 0.4200 - val_loss: 1.8284 - val_accuracy: 0.1562\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 9s 349ms/step - loss: 0.3761 - accuracy: 0.8700 - val_loss: 1.8597 - val_accuracy: 0.1750\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 9s 345ms/step - loss: 0.0909 - accuracy: 0.9800 - val_loss: 1.9448 - val_accuracy: 0.1937\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 9s 343ms/step - loss: 0.0417 - accuracy: 0.9950 - val_loss: 2.0042 - val_accuracy: 0.2313\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 9s 345ms/step - loss: 0.0216 - accuracy: 0.9950 - val_loss: 2.0348 - val_accuracy: 0.2688\n",
      "INFO:tensorflow:Assets written to: models/ravdess_10_softmax/assets\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 9s 342ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 2.0365 - val_accuracy: 0.2625\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 9s 351ms/step - loss: 0.0140 - accuracy: 0.9975 - val_loss: 2.0867 - val_accuracy: 0.3000\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 9s 346ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 2.1182 - val_accuracy: 0.2375\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 9s 343ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.1535 - val_accuracy: 0.2500\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 9s 345ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 2.2058 - val_accuracy: 0.2937\n",
      "INFO:tensorflow:Assets written to: models/ravdess_10_softmax/assets\n"
     ]
    }
   ],
   "source": [
    "#k-Fold training, set for 6 splits\n",
    "\n",
    "n = 0 #current fold\n",
    "\n",
    "epochs = 10\n",
    "function = 'softmax'\n",
    "name = 'ravdess_' + str(epochs) + '_' + function \n",
    "pickle_file = 'pickle_files/' + name + '.pckl'\n",
    "\n",
    "training_score = []\n",
    "testing_score = []\n",
    "\n",
    "f = open(pickle_file, 'wb') #file for saving information/data about each fold\n",
    "\n",
    "\n",
    "kf = KFold(n_splits,shuffle=True,random_state=42)\n",
    "kf.get_n_splits(audio)\n",
    "\n",
    "print(kf)\n",
    "\n",
    "print(audio.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "for train_index, test_index in kf.split(audio):\n",
    "    print('Beginning fold #' + str(n) + '...')\n",
    "    #print(train_index)\n",
    "    #print(test_index)\n",
    "    a_train, a_test = audio[train_index], audio[test_index]\n",
    "    v_train, v_test = video[train_index], video[test_index]\n",
    "    l_train, l_test = labels[train_index], labels[test_index]\n",
    "    \n",
    "    \n",
    "    with strategy.scope():\n",
    "        #fusion layer\n",
    "        aud = Input(audio_input)\n",
    "        vid = Input(video_input)\n",
    "\n",
    "        audio_tensor = audio_cnn_1d(aud)\n",
    "\n",
    "        video_tensor = video_cnn_3d(vid)\n",
    "\n",
    "        fusion = Concatenate()([audio_tensor, video_tensor]) #combining tensors\n",
    "        batch = BatchNormalization()(fusion)\n",
    "        prediction = Dense(6,activation=function)(batch) #softmax\n",
    "        twin_net = Model(inputs=[aud,vid], outputs=prediction)\n",
    "\n",
    "        #Training\n",
    "\n",
    "        checkpoint_filepath = 'models/' + name\n",
    "        model_checkpoint_callback = ModelCheckpoint(\n",
    "            filepath=checkpoint_filepath,\n",
    "            period=5\n",
    "            )\n",
    "        log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + checkpoint_filepath\n",
    "        tensorboard_callback = tensorflow.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "        twin_net.compile(loss='categorical_crossentropy', #categorical_crossentropy\n",
    "                optimizer=optimizers.Adam(learning_rate=0.00001), \n",
    "                         metrics=['accuracy'])\n",
    "\n",
    "        #twin_net.summary()\n",
    "\n",
    "\n",
    "        twin_net.fit([a_train,v_train], l_train,\n",
    "                batch_size=30,\n",
    "                epochs=epochs,\n",
    "                verbose=1,\n",
    "                validation_split=0.166,\n",
    "                callbacks=[model_checkpoint_callback,\n",
    "                tensorboard_callback])\n",
    "        \n",
    "        score = twin_net.evaluate([a_train, v_train], l_train, verbose=0)\n",
    "        pickle.dump([score, 'training accuracy fold # 7/6/2021' + str(n)], f)\n",
    "        training_score.append(score)\n",
    "\n",
    "        score = twin_net.evaluate([a_test, v_test], l_test, verbose=0)\n",
    "        pickle.dump([score, 'testing accuracy fold #' + str(n)], f)\n",
    "        testing_score.append(score)\n",
    "\n",
    "        Y_pred = twin_net.predict([a_test, v_test])\n",
    "        y_pred = np.argmax(Y_pred, axis=1)\n",
    "        labels_ = np.argmax(l_test, axis=1)\n",
    "        pickle.dump(confusion_matrix(labels_, y_pred), f)\n",
    "        pickle.dump(classification_report(labels_, y_pred), f)\n",
    "        \n",
    "        n+=1\n",
    "        \n",
    "    break\n",
    "        \n",
    "f.close()\n",
    "np.savez('data/'+name,x=training_score,y=testing_score)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a94c0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.47655532 0.88645834]] [[0.59111792 0.828125  ]]\n",
      "[[0.47655531764030457, 0.8864583373069763], 'training accuracy fold # 7/6/20210']\n",
      "[[0.5911179184913635, 0.828125], 'testing accuracy fold #0']\n",
      "[[31  0  1  0  0  0]\n",
      " [ 2 26  1  1  4  0]\n",
      " [ 4  0 24  0  4  0]\n",
      " [ 0  0  1 22  3  2]\n",
      " [ 0  0  1  0 30  0]\n",
      " [ 2  0  3  1  3 26]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.97      0.87        32\n",
      "           1       1.00      0.76      0.87        34\n",
      "           2       0.77      0.75      0.76        32\n",
      "           3       0.92      0.79      0.85        28\n",
      "           4       0.68      0.97      0.80        31\n",
      "           5       0.93      0.74      0.83        35\n",
      "\n",
      "    accuracy                           0.83       192\n",
      "   macro avg       0.85      0.83      0.83       192\n",
      "weighted avg       0.85      0.83      0.83       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "load = np.load('data/'+name+'.npz')\n",
    "training_score = load['x']\n",
    "testing_score = load['y']\n",
    "\n",
    "print(training_score,testing_score)\n",
    "#print('testing_score loss:', np.mean(testing_score[0]))\n",
    "#print('testing_score accuracy:',np.mean(testing_score[1]))\n",
    "\n",
    "\n",
    "\n",
    "f.close()\n",
    "\n",
    "with (open(pickle_file, \"rb\")) as openfile:\n",
    "    while True:\n",
    "        try:\n",
    "            print(pickle.load(openfile))\n",
    "        except EOFError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0cd927",
   "metadata": {},
   "source": [
    "INFO:tensorflow:Assets written to: models/ravdess_30_sigmoid/assets\n",
    "[[0.3629540205001831, 0.8600000143051147], 'training accuracy fold #0']\n",
    "[[0.5187535285949707, 0.7833333611488342], 'testing accuracy fold #0']\n",
    "[[15  0  0  1  0  1  0  0]\n",
    " [ 2 32  0  2  0  2  0  0]\n",
    " [ 0  0 25  2  0  2  3  0]\n",
    " [ 2  0  0 19  5  3  1  0]\n",
    " [ 0  1  0  2 27  1  0  0]\n",
    " [ 2  2  0  0  2 20  2  0]\n",
    " [ 0  0  0  0  2  3 25  0]\n",
    " [ 0  0  4  2  0  1  2 25]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           1       0.71      0.88      0.79        17\n",
    "           2       0.91      0.84      0.88        38\n",
    "           3       0.86      0.78      0.82        32\n",
    "           4       0.68      0.63      0.66        30\n",
    "           5       0.75      0.87      0.81        31\n",
    "           6       0.61      0.71      0.66        28\n",
    "           7       0.76      0.83      0.79        30\n",
    "           8       1.00      0.74      0.85        34\n",
    "\n",
    "    accuracy                           0.78       240\n",
    "   macro avg       0.79      0.79      0.78       240\n",
    "weighted avg       0.80      0.78      0.79       240\n",
    "\n",
    "[[0.3796142041683197, 0.8700000047683716], 'training accuracy fold #1']\n",
    "[[0.5539751648902893, 0.7708333134651184], 'testing accuracy fold #1']\n",
    "[[19  0  0  0  1  0  0  0]\n",
    " [ 0 20  0  0  0  3  0  0]\n",
    " [ 0  1 29  0  4  1  1  2]\n",
    " [ 2  0  0 26  2  3  0  2]\n",
    " [ 0  1  0  0 24  5  0  0]\n",
    " [ 1  0  0  1  3 23  3  1]\n",
    " [ 0  0  0  0  5  5 27  0]\n",
    " [ 0  1  0  0  3  2  2 17]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           1       0.86      0.95      0.90        20\n",
    "           2       0.87      0.87      0.87        23\n",
    "           3       1.00      0.76      0.87        38\n",
    "           4       0.96      0.74      0.84        35\n",
    "           5       0.57      0.80      0.67        30\n",
    "           6       0.55      0.72      0.62        32\n",
    "           7       0.82      0.73      0.77        37\n",
    "           8       0.77      0.68      0.72        25\n",
    "\n",
    "    accuracy                           0.77       240\n",
    "   macro avg       0.80      0.78      0.78       240\n",
    "weighted avg       0.81      0.77      0.78       240\n",
    "\n",
    "[[0.37501320242881775, 0.8641666769981384], 'training accuracy fold #2']\n",
    "[[0.47459012269973755, 0.7916666865348816], 'testing accuracy fold #2']\n",
    "[[12  0  0  0  1  1  0  0]\n",
    " [ 2 28  2  0  0  2  0  1]\n",
    " [ 2  0 26  0  2  2  0  1]\n",
    " [ 0  0  0 23  3  0  2  1]\n",
    " [ 0  2  0  3 25  0  0  0]\n",
    " [ 0  0  0  2  4 17  2  0]\n",
    " [ 0  0  0  2  2  2 27  2]\n",
    " [ 0  0  0  1  3  2  1 32]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           1       0.75      0.86      0.80        14\n",
    "           2       0.93      0.80      0.86        35\n",
    "           3       0.93      0.79      0.85        33\n",
    "           4       0.74      0.79      0.77        29\n",
    "           5       0.62      0.83      0.71        30\n",
    "           6       0.65      0.68      0.67        25\n",
    "           7       0.84      0.77      0.81        35\n",
    "           8       0.86      0.82      0.84        39\n",
    "\n",
    "    accuracy                           0.79       240\n",
    "   macro avg       0.79      0.79      0.79       240\n",
    "weighted avg       0.81      0.79      0.80       240\n",
    "\n",
    "[[0.3411281406879425, 0.8633333444595337], 'training accuracy fold #3']\n",
    "[[0.5509750247001648, 0.7791666388511658], 'testing accuracy fold #3']\n",
    "[[ 8  2  0  1  0  0  0  1]\n",
    " [ 0 23  0  4  0  1  0  1]\n",
    " [ 0  0 29  1  3  1  0  2]\n",
    " [ 0  2  0 30  5  4  0  2]\n",
    " [ 0  1  2  1 32  3  0  0]\n",
    " [ 0  1  0  0  4 24  0  0]\n",
    " [ 0  0  0  2  2  0 15  0]\n",
    " [ 0  3  0  1  2  0  1 26]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           1       1.00      0.67      0.80        12\n",
    "           2       0.72      0.79      0.75        29\n",
    "           3       0.94      0.81      0.87        36\n",
    "           4       0.75      0.70      0.72        43\n",
    "           5       0.67      0.82      0.74        39\n",
    "           6       0.73      0.83      0.77        29\n",
    "           7       0.94      0.79      0.86        19\n",
    "           8       0.81      0.79      0.80        33\n",
    "\n",
    "    accuracy                           0.78       240\n",
    "   macro avg       0.82      0.77      0.79       240\n",
    "weighted avg       0.79      0.78      0.78       240\n",
    "\n",
    "[[0.36666935682296753, 0.8608333468437195], 'training accuracy fold #4']\n",
    "[[0.4919424057006836, 0.800000011920929], 'testing accuracy fold #4']\n",
    "[[11  1  0  1  1  0  0  0]\n",
    " [ 4 34  0  2  5  1  0  0]\n",
    " [ 0  2 15  2  1  1  0  0]\n",
    " [ 0  0  0 20  2  2  0  0]\n",
    " [ 1  0  0  2 20  5  0  0]\n",
    " [ 0  0  0  0  2 34  0  0]\n",
    " [ 0  0  0  4  3  1 31  0]\n",
    " [ 0  0  0  0  2  1  2 27]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           1       0.69      0.79      0.73        14\n",
    "           2       0.92      0.74      0.82        46\n",
    "           3       1.00      0.71      0.83        21\n",
    "           4       0.65      0.83      0.73        24\n",
    "           5       0.56      0.71      0.63        28\n",
    "           6       0.76      0.94      0.84        36\n",
    "           7       0.94      0.79      0.86        39\n",
    "           8       1.00      0.84      0.92        32\n",
    "\n",
    "    accuracy                           0.80       240\n",
    "   macro avg       0.81      0.80      0.79       240\n",
    "weighted avg       0.83      0.80      0.81       240\n",
    "\n",
    "[[0.3825329542160034, 0.8700000047683716], 'training accuracy fold #5']\n",
    "[[0.580239474773407, 0.7916666865348816], 'testing accuracy fold #5']\n",
    "[[15  0  0  1  2  1  0  0]\n",
    " [ 0 18  0  0  1  2  0  0]\n",
    " [ 0  0 26  0  4  2  0  0]\n",
    " [ 0  0  0 23  6  0  0  2]\n",
    " [ 0  0  0  0 33  1  0  0]\n",
    " [ 0  3  0  2  5 32  0  0]\n",
    " [ 1  0  0  2  2  4 22  1]\n",
    " [ 0  0  0  0  6  2  0 21]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           1       0.94      0.79      0.86        19\n",
    "           2       0.86      0.86      0.86        21\n",
    "           3       1.00      0.81      0.90        32\n",
    "           4       0.82      0.74      0.78        31\n",
    "           5       0.56      0.97      0.71        34\n",
    "           6       0.73      0.76      0.74        42\n",
    "           7       1.00      0.69      0.81        32\n",
    "           8       0.88      0.72      0.79        29\n",
    "\n",
    "    accuracy                           0.79       240\n",
    "   macro avg       0.85      0.79      0.81       240\n",
    "weighted avg       0.83      0.79      0.80       240"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c3b692",
   "metadata": {},
   "outputs": [],
   "source": [
    "with (open(pickle_file, \"rb\")) as openfile:\n",
    "    while True:\n",
    "        try:\n",
    "            print(pickle.load(openfile))\n",
    "        except EOFError:\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patient-western",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    #test sigmoid\n",
    "    model = load_model('models/ravdess_softmax_extended')\n",
    "\n",
    "\n",
    "    score = model.evaluate([a_train, v_train], l_train, verbose=0)\n",
    "    print(\"Training Accuracy: \", score)\n",
    "\n",
    "    score = model.evaluate([a_test, v_test], l_test, verbose=0)\n",
    "    print(\"Testing Accuracy: \", score)\n",
    "\n",
    "\n",
    "    Y_pred = model.predict([a_test, v_test])\n",
    "    y_pred = np.argmax(Y_pred, axis=1)\n",
    "    labels = np.argmax(l_test, axis=1)\n",
    "    print('Confusion_Matrix')\n",
    "    print(confusion_matrix(labels, y_pred))\n",
    "\n",
    "    print('Classification Report')\n",
    "    print(classification_report(labels, y_pred, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d3424e",
   "metadata": {},
   "source": [
    "300 epoch softmax\n",
    "Training Accuracy:  [0.3390514552593231, 0.9666666388511658]\n",
    "Testing Accuracy:  [2.35433292388916, 0.7958333492279053]\n",
    "Confusion_Matrix\n",
    "[[17  0  0  0  0  0  0  0]\n",
    " [ 3 31  0  0  2  0  1  1]\n",
    " [ 0  0 23  4  0  1  2  2]\n",
    " [ 2  0  2 22  2  0  1  1]\n",
    " [ 0  0  0  3 27  0  0  1]\n",
    " [ 3  2  0  0  2 18  3  0]\n",
    " [ 0  0  0  1  0  2 27  0]\n",
    " [ 0  1  3  1  0  0  3 26]]\n",
    "Classification Report\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "     neutral       0.68      1.00      0.81        17\n",
    "        calm       0.91      0.82      0.86        38\n",
    "       happy       0.82      0.72      0.77        32\n",
    "         sad       0.71      0.73      0.72        30\n",
    "       angry       0.82      0.87      0.84        31\n",
    "     fearful       0.86      0.64      0.73        28\n",
    "     disgust       0.73      0.90      0.81        30\n",
    "   surprised       0.84      0.76      0.80        34\n",
    "\n",
    "    accuracy                           0.80       240\n",
    "   macro avg       0.80      0.81      0.79       240\n",
    "weighted avg       0.81      0.80      0.79       240\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa61b8cb",
   "metadata": {},
   "source": [
    "Training Accuracy:  [0.3390514552593231, 0.9666666388511658]\n",
    "Testing Accuracy:  [2.35433292388916, 0.7958333492279053]\n",
    "Confusion_Matrix\n",
    "[[17  0  0  0  0  0  0  0]\n",
    " [ 3 31  0  0  2  0  1  1]\n",
    " [ 0  0 23  4  0  1  2  2]\n",
    " [ 2  0  2 22  2  0  1  1]\n",
    " [ 0  0  0  3 27  0  0  1]\n",
    " [ 3  2  0  0  2 18  3  0]\n",
    " [ 0  0  0  1  0  2 27  0]\n",
    " [ 0  1  3  1  0  0  3 26]]\n",
    "Classification Report\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "     neutral       0.68      1.00      0.81        17\n",
    "        calm       0.91      0.82      0.86        38\n",
    "       happy       0.82      0.72      0.77        32\n",
    "         sad       0.71      0.73      0.72        30\n",
    "       angry       0.82      0.87      0.84        31\n",
    "     fearful       0.86      0.64      0.73        28\n",
    "     disgust       0.73      0.90      0.81        30\n",
    "   surprised       0.84      0.76      0.80        34\n",
    "\n",
    "    accuracy                           0.80       240\n",
    "   macro avg       0.80      0.81      0.79       240\n",
    "weighted avg       0.81      0.80      0.79       240"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aaae41d",
   "metadata": {},
   "source": [
    "sigmoid 300 ravdess\n",
    "Training Accuracy:  [0.019113920629024506, 0.9758333563804626]\n",
    "Testing Accuracy:  [0.13955293595790863, 0.8541666865348816]\n",
    "Confusion_Matrix\n",
    "[[17  0  0  0  0  0  0  0]\n",
    " [ 0 35  1  1  0  0  0  1]\n",
    " [ 0  0 29  0  0  0  2  1]\n",
    " [ 0  2  2 22  2  0  1  1]\n",
    " [ 0  0  0  2 27  0  1  1]\n",
    " [ 0  1  0  1  2 21  3  0]\n",
    " [ 0  0  0  1  1  2 26  0]\n",
    " [ 0  0  4  0  0  0  2 28]]\n",
    "Classification Report\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "     neutral       1.00      1.00      1.00        17\n",
    "        calm       0.92      0.92      0.92        38\n",
    "       happy       0.81      0.91      0.85        32\n",
    "         sad       0.81      0.73      0.77        30\n",
    "       angry       0.84      0.87      0.86        31\n",
    "     fearful       0.91      0.75      0.82        28\n",
    "     disgust       0.74      0.87      0.80        30\n",
    "   surprised       0.88      0.82      0.85        34\n",
    "\n",
    "    accuracy                           0.85       240\n",
    "   macro avg       0.86      0.86      0.86       240\n",
    "weighted avg       0.86      0.85      0.85       240\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41317fc",
   "metadata": {},
   "source": [
    "sigmoid\n",
    "Training Accuracy:  [0.15417054295539856, 0.9775000214576721]\n",
    "Testing Accuracy:  [0.3786163330078125, 0.824999988079071]\n",
    "Confusion_Matrix\n",
    "[[17  0  0  0  0  0  0  0]\n",
    " [ 0 35  1  0  0  1  0  1]\n",
    " [ 0  4 24  0  0  2  2  0]\n",
    " [ 2  0  2 22  2  0  1  1]\n",
    " [ 0  0  0  1 29  0  0  1]\n",
    " [ 2  0  2  0  0 20  4  0]\n",
    " [ 0  0  1  1  0  2 26  0]\n",
    " [ 0  0  5  0  0  1  3 25]]\n",
    "Classification Report\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "     neutral       0.81      1.00      0.89        17\n",
    "        calm       0.90      0.92      0.91        38\n",
    "       happy       0.69      0.75      0.72        32\n",
    "         sad       0.92      0.73      0.81        30\n",
    "       angry       0.94      0.94      0.94        31\n",
    "     fearful       0.77      0.71      0.74        28\n",
    "     disgust       0.72      0.87      0.79        30\n",
    "   surprised       0.89      0.74      0.81        34\n",
    "\n",
    "    accuracy                           0.82       240\n",
    "   macro avg       0.83      0.83      0.83       240\n",
    "weighted avg       0.83      0.82      0.82       240\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "differential-emission",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#test softmax\n",
    "model = load_model('models/twin_net_softmax')\n",
    "\n",
    "\n",
    "score = model.evaluate([a_train, v_train], l_train, verbose=0)\n",
    "print(\"Training Accuracy: \", score)\n",
    "\n",
    "score = model.evaluate([a_test, v_test], l_test, verbose=0)\n",
    "print(\"Testing Accuracy: \", score)\n",
    "\n",
    "\n",
    "Y_pred = model.predict([a_test, v_test])\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "labels = np.argmax(l_test, axis=1)\n",
    "print('Confusion_Matrix')\n",
    "print(confusion_matrix(labels, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
