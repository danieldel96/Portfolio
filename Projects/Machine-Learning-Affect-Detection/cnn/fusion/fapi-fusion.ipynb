{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "painted-tonight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 128, 128, 16, 1)\n",
      "(320,)\n",
      "(320, 105211, 1)\n",
      "Model: \"model_45\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_69 (InputLayer)        [(None, 105211, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv1d_85 (Conv1D)           (None, 13152, 25)         1625      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_187 (LeakyReLU)  (None, 13152, 25)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_86 (Conv1D)           (None, 1644, 25)          80025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_168 (Bat (None, 1644, 25)          100       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_188 (LeakyReLU)  (None, 1644, 25)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_87 (Conv1D)           (None, 206, 25)           160025    \n",
      "_________________________________________________________________\n",
      "batch_normalization_169 (Bat (None, 206, 25)           100       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_189 (LeakyReLU)  (None, 206, 25)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_88 (Conv1D)           (None, 52, 25)            320025    \n",
      "_________________________________________________________________\n",
      "batch_normalization_170 (Bat (None, 52, 25)            100       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_190 (LeakyReLU)  (None, 52, 25)            0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_191 (LeakyReLU)  (None, 52, 25)            0         \n",
      "_________________________________________________________________\n",
      "flatten_34 (Flatten)         (None, 1300)              0         \n",
      "=================================================================\n",
      "Total params: 562,000\n",
      "Trainable params: 561,850\n",
      "Non-trainable params: 150\n",
      "_________________________________________________________________\n",
      "Model: \"model_46\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_70 (InputLayer)        [(None, 128, 128, 16, 1)] 0         \n",
      "_________________________________________________________________\n",
      "conv3d_102 (Conv3D)          (None, 63, 63, 14, 64)    1792      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_192 (LeakyReLU)  (None, 63, 63, 14, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_103 (Conv3D)          (None, 32, 32, 14, 128)   221312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_172 (Bat (None, 32, 32, 14, 128)   512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_193 (LeakyReLU)  (None, 32, 32, 14, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv3d_104 (Conv3D)          (None, 16, 16, 14, 256)   884992    \n",
      "_________________________________________________________________\n",
      "batch_normalization_173 (Bat (None, 16, 16, 14, 256)   1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_194 (LeakyReLU)  (None, 16, 16, 14, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv3d_105 (Conv3D)          (None, 8, 8, 7, 512)      3539456   \n",
      "_________________________________________________________________\n",
      "batch_normalization_174 (Bat (None, 8, 8, 7, 512)      2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_195 (LeakyReLU)  (None, 8, 8, 7, 512)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_106 (Conv3D)          (None, 4, 4, 4, 1024)     14156800  \n",
      "_________________________________________________________________\n",
      "batch_normalization_175 (Bat (None, 4, 4, 4, 1024)     4096      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_196 (LeakyReLU)  (None, 4, 4, 4, 1024)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_107 (Conv3D)          (None, 2, 2, 2, 2048)     56625152  \n",
      "_________________________________________________________________\n",
      "batch_normalization_176 (Bat (None, 2, 2, 2, 2048)     8192      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_197 (LeakyReLU)  (None, 2, 2, 2, 2048)     0         \n",
      "_________________________________________________________________\n",
      "flatten_35 (Flatten)         (None, 16384)             0         \n",
      "=================================================================\n",
      "Total params: 75,445,376\n",
      "Trainable params: 75,437,440\n",
      "Non-trainable params: 7,936\n",
      "_________________________________________________________________\n",
      "Model: \"model_47\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_71 (InputLayer)           [(None, 105211, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_72 (InputLayer)           [(None, 128, 128, 16 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_45 (Functional)           (None, 1300)         562000      input_71[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_46 (Functional)           (None, 16384)        75445376    input_72[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 17684)        0           model_45[0][0]                   \n",
      "                                                                 model_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, 17684)        70736       concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_34 (Dense)                (None, 1)            17685       batch_normalization_177[0][0]    \n",
      "==================================================================================================\n",
      "Total params: 76,095,797\n",
      "Trainable params: 76,052,343\n",
      "Non-trainable params: 43,454\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/30\n",
      "9/9 [==============================] - 7s 545ms/step - loss: 0.8349 - accuracy: 0.5189 - val_loss: 0.6695 - val_accuracy: 0.4375\n",
      "Epoch 2/30\n",
      "9/9 [==============================] - 3s 328ms/step - loss: 0.2147 - accuracy: 0.4882 - val_loss: 0.6336 - val_accuracy: 0.4375\n",
      "Epoch 3/30\n",
      "9/9 [==============================] - 3s 326ms/step - loss: 0.0912 - accuracy: 0.5259 - val_loss: 0.6196 - val_accuracy: 0.4375\n",
      "Epoch 4/30\n",
      "9/9 [==============================] - 3s 323ms/step - loss: 0.0315 - accuracy: 0.4957 - val_loss: 0.6089 - val_accuracy: 0.4375\n",
      "Epoch 5/30\n",
      "9/9 [==============================] - 3s 323ms/step - loss: 0.0139 - accuracy: 0.5088 - val_loss: 0.6021 - val_accuracy: 0.4375\n",
      "Epoch 6/30\n",
      "9/9 [==============================] - 3s 322ms/step - loss: 0.0064 - accuracy: 0.4836 - val_loss: 0.5982 - val_accuracy: 0.4375\n",
      "Epoch 7/30\n",
      "9/9 [==============================] - 3s 327ms/step - loss: 0.0023 - accuracy: 0.5202 - val_loss: 0.5883 - val_accuracy: 0.4375\n",
      "Epoch 8/30\n",
      "6/9 [===================>..........] - ETA: 0s - loss: 0.0022 - accuracy: 0.5290"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-13ec97320c6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0mtwin_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m twin_net.fit([a_train,v_train], l_train,\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1103\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \"\"\"\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    294\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lib/python3.8/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lib/python3.8/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    508\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1069\u001b[0m     \"\"\"\n\u001b[1;32m   1070\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1035\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Sequential model // doesnt work, refer to sequential vs. functional api\n",
    "#Functional api's handle multiple inputs better, sequential cannot create model with multiple inputs\n",
    "import keras\n",
    "import tensorflow\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import Conv3D\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers import Input\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "load = np.load('data/RAVDESS.npz')\n",
    "audio = load['audio']\n",
    "video = load['video']\n",
    "labels = load['labels']\n",
    "\n",
    "#video pre-process\n",
    "fraction = 5\n",
    "frames = int(80/fraction)\n",
    "shape = (128,128,frames,1)\n",
    "\n",
    "reshape_videos = []\n",
    "\n",
    "for i in video:\n",
    "    single_video = []\n",
    "    for j in range( i.shape[0] ): #HEREi.shape[0]\n",
    "        if(  j % fraction == 0 ):\n",
    "            single_video.append( i[j] )\n",
    "    reshape_videos.append( single_video )\n",
    "\n",
    "video = np.array(reshape_videos)\n",
    "del reshape_videos\n",
    "\n",
    "video_input = (128, 128, frames, 1)\n",
    "video_shape = (video.shape[0], 128, 128, frames, 1)\n",
    "video = np.reshape(video, video_shape)\n",
    "####################\n",
    "\n",
    "\n",
    "#audio pre-process\n",
    "num_rows = 105211\n",
    "num_columns = 1\n",
    "num_channels = 1\n",
    "\n",
    "audio_input = (num_rows, num_columns)\n",
    "audio_shape = (audio.shape[0], num_rows, num_columns)\n",
    "audio = np.reshape(audio, audio_shape)\n",
    "###################\n",
    "\n",
    "\n",
    "v_train, v_test, a_train, a_test, l_train, l_test = train_test_split(video, \n",
    "                                                                     audio, \n",
    "                                                                     labels,\n",
    "                                                                     test_size=0.166,\n",
    "                                                                     random_state=42) #size=0.2\n",
    "\n",
    "print(v_train.shape)\n",
    "print(l_train.shape)\n",
    "print(a_train.shape)\n",
    "\n",
    "\n",
    "def audio_cnn_1d(sample_shape):\n",
    "    #Layer 1\n",
    "    input_ = Input(shape=sample_shape)\n",
    "    conv1d = Conv1D(padding='same', filters=25, kernel_size=64, strides = 8, input_shape=sample_shape)(input_)\n",
    "    relu = LeakyReLU(alpha=0.2)(conv1d)\n",
    "    \n",
    "    #Layer 2\n",
    "    conv1d = Conv1D(padding='same', filters=25, kernel_size=128, strides = 8)(relu)\n",
    "    batch = BatchNormalization()(conv1d)\n",
    "    relu = LeakyReLU(alpha=0.2)(batch)\n",
    "    \n",
    "    #Layer 3\n",
    "    conv1d = Conv1D(padding='same', filters=25, kernel_size=256, strides = 8)(relu)\n",
    "    batch = BatchNormalization()(conv1d)\n",
    "    relu = LeakyReLU(alpha=0.2)(batch)\n",
    "    \n",
    "    #Layer 4\n",
    "    conv1d = Conv1D(padding='same', filters=25, kernel_size=512, strides = 4)(relu)\n",
    "    batch = BatchNormalization()(conv1d)\n",
    "    relu = LeakyReLU(alpha=0.2)(batch)\n",
    "    \n",
    "    #Layer 5\n",
    "    conv1d = Conv1D(padding='same', filters=25, kernel_size=1024, strides = 4)(relu)\n",
    "    batch = BatchNormalization()(conv1d)\n",
    "    relu = LeakyReLU(alpha=0.2)(relu)\n",
    "    \n",
    "    #layer 6\n",
    "    output = Flatten()(relu)\n",
    "    \n",
    "    model = Model(inputs=[input_], outputs=[output] )\n",
    "    return model\n",
    "\n",
    "#video neural network\n",
    "def video_cnn_3d(sample_shape):\n",
    "    input_ = Input(shape=sample_shape)\n",
    "    #layer 1\n",
    "    conv3d = Conv3D(64, kernel_size=(3,3,3), strides=(2,2,1), input_shape=sample_shape)(input_)\n",
    "    relu = LeakyReLU(alpha=0.2)(conv3d)\n",
    "    \n",
    "    #layer 2\n",
    "    conv3d = Conv3D(128, kernel_size=(3,3,3), strides=(2,2,1), padding='SAME')(relu)\n",
    "    batch = BatchNormalization()(conv3d)\n",
    "    relu = LeakyReLU(alpha=0.2)(batch)\n",
    "    \n",
    "    #layer 3\n",
    "    conv3d = Conv3D(256, kernel_size=(3,3,3), strides=(2,2,1), padding='SAME')(relu)\n",
    "    batch = BatchNormalization()(conv3d)\n",
    "    relu = LeakyReLU(alpha=0.2)(batch)\n",
    "\n",
    "    #layer 4\n",
    "    conv3d = Conv3D(512, kernel_size=(3,3,3), strides=(2,2,2), padding='SAME')(relu)\n",
    "    batch = BatchNormalization()(conv3d)\n",
    "    relu = LeakyReLU(alpha=0.2)(batch)\n",
    "\n",
    "    #layer 5\n",
    "    conv3d = Conv3D(1024, kernel_size=(3,3,3), strides=(2,2,2), padding='SAME')(relu)\n",
    "    batch = BatchNormalization()(conv3d)\n",
    "    relu = LeakyReLU(alpha=0.2)(batch)\n",
    "\n",
    "    #layer 6\n",
    "    conv3d = Conv3D(2048, kernel_size=(3,3,3), strides=(2,2,2), padding='SAME')(relu)\n",
    "    batch = BatchNormalization()(conv3d)\n",
    "    relu = LeakyReLU(alpha=0.2)(batch)\n",
    "\n",
    "    #layer 7\n",
    "    output = Flatten()(relu)\n",
    "    model = Model(inputs=[input_], outputs=[output] )\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "audio_model = audio_cnn_1d(audio_input)\n",
    "audio_model.summary()\n",
    "\n",
    "video_model = video_cnn_3d(video_input)\n",
    "video_model.summary()\n",
    "\n",
    "\n",
    "left_input = Input(audio_input)\n",
    "right_input = Input(video_input)\n",
    "\n",
    "l_encoded = audio_model(left_input)\n",
    "r_encoded = video_model(right_input)\n",
    "\n",
    "#fusion layer\n",
    "fusion = Concatenate()([l_encoded,r_encoded])\n",
    "batch = BatchNormalization()(fusion)\n",
    "prediction = Dense(1,activation='softmax')(batch)\n",
    "twin_net = Model([left_input,right_input],prediction)\n",
    "\n",
    "\n",
    "twin_net.compile(loss='binary_crossentropy',\n",
    "        optimizer=optimizers.Adam(lr=0.00001),metrics=['accuracy'])\n",
    "\n",
    "twin_net.summary()\n",
    "\n",
    "twin_net.fit([a_train,v_train], l_train,\n",
    "        batch_size=30,\n",
    "        epochs=30,\n",
    "        verbose=1,\n",
    "        validation_split=0.166)\n",
    "\n",
    "twin_net.save('models/twin_net_softmax')\n",
    "\n",
    "\n",
    "#test\n",
    "model = load_model('models/twin_net_softmax')\n",
    "\n",
    "\n",
    "score = model.evaluate([a_train, v_train], l_train, verbose=0)\n",
    "print(\"Training Accuracy: \", score)\n",
    "\n",
    "score = model.evaluate([a_test, v_test], l_test, verbose=1)\n",
    "print(\"Testing Accuracy: \", score)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "commercial-privilege",
   "metadata": {},
   "outputs": [],
   "source": [
    "(320, 128, 128, 16, 1)\n",
    "(320,)\n",
    "(320, 105211, 1)\n",
    "Model: \"model_39\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "input_61 (InputLayer)        [(None, 105211, 1)]       0         \n",
    "_________________________________________________________________\n",
    "conv1d_75 (Conv1D)           (None, 13152, 25)         1625      \n",
    "_________________________________________________________________\n",
    "leaky_re_lu_165 (LeakyReLU)  (None, 13152, 25)         0         \n",
    "_________________________________________________________________\n",
    "conv1d_76 (Conv1D)           (None, 1644, 25)          80025     \n",
    "_________________________________________________________________\n",
    "batch_normalization_148 (Bat (None, 1644, 25)          100       \n",
    "_________________________________________________________________\n",
    "leaky_re_lu_166 (LeakyReLU)  (None, 1644, 25)          0         \n",
    "_________________________________________________________________\n",
    "conv1d_77 (Conv1D)           (None, 206, 25)           160025    \n",
    "_________________________________________________________________\n",
    "batch_normalization_149 (Bat (None, 206, 25)           100       \n",
    "_________________________________________________________________\n",
    "leaky_re_lu_167 (LeakyReLU)  (None, 206, 25)           0         \n",
    "_________________________________________________________________\n",
    "conv1d_78 (Conv1D)           (None, 52, 25)            320025    \n",
    "_________________________________________________________________\n",
    "batch_normalization_150 (Bat (None, 52, 25)            100       \n",
    "_________________________________________________________________\n",
    "leaky_re_lu_168 (LeakyReLU)  (None, 52, 25)            0         \n",
    "_________________________________________________________________\n",
    "leaky_re_lu_169 (LeakyReLU)  (None, 52, 25)            0         \n",
    "_________________________________________________________________\n",
    "flatten_30 (Flatten)         (None, 1300)              0         \n",
    "=================================================================\n",
    "Total params: 562,000\n",
    "Trainable params: 561,850\n",
    "Non-trainable params: 150\n",
    "_________________________________________________________________\n",
    "Model: \"model_40\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "input_62 (InputLayer)        [(None, 128, 128, 16, 1)] 0         \n",
    "_________________________________________________________________\n",
    "conv3d_90 (Conv3D)           (None, 63, 63, 14, 64)    1792      \n",
    "_________________________________________________________________\n",
    "leaky_re_lu_170 (LeakyReLU)  (None, 63, 63, 14, 64)    0         \n",
    "_________________________________________________________________\n",
    "conv3d_91 (Conv3D)           (None, 32, 32, 14, 128)   221312    \n",
    "_________________________________________________________________\n",
    "batch_normalization_152 (Bat (None, 32, 32, 14, 128)   512       \n",
    "_________________________________________________________________\n",
    "leaky_re_lu_171 (LeakyReLU)  (None, 32, 32, 14, 128)   0         \n",
    "_________________________________________________________________\n",
    "conv3d_92 (Conv3D)           (None, 16, 16, 14, 256)   884992    \n",
    "_________________________________________________________________\n",
    "batch_normalization_153 (Bat (None, 16, 16, 14, 256)   1024      \n",
    "_________________________________________________________________\n",
    "leaky_re_lu_172 (LeakyReLU)  (None, 16, 16, 14, 256)   0         \n",
    "_________________________________________________________________\n",
    "conv3d_93 (Conv3D)           (None, 8, 8, 7, 512)      3539456   \n",
    "_________________________________________________________________\n",
    "batch_normalization_154 (Bat (None, 8, 8, 7, 512)      2048      \n",
    "_________________________________________________________________\n",
    "leaky_re_lu_173 (LeakyReLU)  (None, 8, 8, 7, 512)      0         \n",
    "_________________________________________________________________\n",
    "conv3d_94 (Conv3D)           (None, 4, 4, 4, 1024)     14156800  \n",
    "_________________________________________________________________\n",
    "batch_normalization_155 (Bat (None, 4, 4, 4, 1024)     4096      \n",
    "_________________________________________________________________\n",
    "leaky_re_lu_174 (LeakyReLU)  (None, 4, 4, 4, 1024)     0         \n",
    "_________________________________________________________________\n",
    "conv3d_95 (Conv3D)           (None, 2, 2, 2, 2048)     56625152  \n",
    "_________________________________________________________________\n",
    "batch_normalization_156 (Bat (None, 2, 2, 2, 2048)     8192      \n",
    "_________________________________________________________________\n",
    "leaky_re_lu_175 (LeakyReLU)  (None, 2, 2, 2, 2048)     0         \n",
    "_________________________________________________________________\n",
    "flatten_31 (Flatten)         (None, 16384)             0         \n",
    "=================================================================\n",
    "Total params: 75,445,376\n",
    "Trainable params: 75,437,440\n",
    "Non-trainable params: 7,936\n",
    "_________________________________________________________________\n",
    "Model: \"model_41\"\n",
    "__________________________________________________________________________________________________\n",
    "Layer (type)                    Output Shape         Param #     Connected to                     \n",
    "==================================================================================================\n",
    "input_63 (InputLayer)           [(None, 105211, 1)]  0                                            \n",
    "__________________________________________________________________________________________________\n",
    "input_64 (InputLayer)           [(None, 128, 128, 16 0                                            \n",
    "__________________________________________________________________________________________________\n",
    "model_39 (Functional)           (None, 1300)         562000      input_63[0][0]                   \n",
    "__________________________________________________________________________________________________\n",
    "model_40 (Functional)           (None, 16384)        75445376    input_64[0][0]                   \n",
    "__________________________________________________________________________________________________\n",
    "concatenate_14 (Concatenate)    (None, 17684)        0           model_39[0][0]                   \n",
    "                                                                 model_40[0][0]                   \n",
    "__________________________________________________________________________________________________\n",
    "batch_normalization_157 (BatchN (None, 17684)        70736       concatenate_14[0][0]             \n",
    "__________________________________________________________________________________________________\n",
    "dense_32 (Dense)                (None, 1)            17685       batch_normalization_157[0][0]    \n",
    "==================================================================================================\n",
    "Total params: 76,095,797\n",
    "Trainable params: 76,052,343\n",
    "Non-trainable params: 43,454\n",
    "__________________________________________________________________________________________________\n",
    "Epoch 1/30\n",
    "9/9 [==============================] - 5s 370ms/step - loss: 0.7571 - accuracy: 0.6567 - val_loss: 0.6352 - val_accuracy: 0.6667\n",
    "Epoch 2/30\n",
    "9/9 [==============================] - 3s 330ms/step - loss: 0.1549 - accuracy: 0.9234 - val_loss: 0.6179 - val_accuracy: 0.6111\n",
    "Epoch 3/30\n",
    "9/9 [==============================] - 3s 328ms/step - loss: 0.0381 - accuracy: 0.9826 - val_loss: 0.6149 - val_accuracy: 0.5741\n",
    "Epoch 4/30\n",
    "9/9 [==============================] - 3s 329ms/step - loss: 0.0125 - accuracy: 0.9984 - val_loss: 0.6148 - val_accuracy: 0.5741\n",
    "Epoch 5/30\n",
    "9/9 [==============================] - 3s 329ms/step - loss: 0.0033 - accuracy: 0.9978 - val_loss: 0.6057 - val_accuracy: 0.5741\n",
    "Epoch 6/30\n",
    "9/9 [==============================] - 3s 328ms/step - loss: 0.0085 - accuracy: 0.9952 - val_loss: 0.5948 - val_accuracy: 0.5741\n",
    "Epoch 7/30\n",
    "9/9 [==============================] - 3s 335ms/step - loss: 0.0105 - accuracy: 0.9902 - val_loss: 0.5793 - val_accuracy: 0.6111\n",
    "Epoch 8/30\n",
    "9/9 [==============================] - 3s 346ms/step - loss: 8.3730e-04 - accuracy: 1.0000 - val_loss: 0.5642 - val_accuracy: 0.6481\n",
    "Epoch 9/30\n",
    "9/9 [==============================] - 3s 353ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5407 - val_accuracy: 0.6852\n",
    "Epoch 10/30\n",
    "9/9 [==============================] - 3s 343ms/step - loss: 2.2556e-04 - accuracy: 1.0000 - val_loss: 0.5148 - val_accuracy: 0.7037\n",
    "Epoch 11/30\n",
    "9/9 [==============================] - 3s 335ms/step - loss: 0.0025 - accuracy: 0.9984 - val_loss: 0.4896 - val_accuracy: 0.7407\n",
    "Epoch 12/30\n",
    "9/9 [==============================] - 3s 333ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4658 - val_accuracy: 0.7593\n",
    "Epoch 13/30\n",
    "9/9 [==============================] - 3s 332ms/step - loss: 2.8409e-04 - accuracy: 1.0000 - val_loss: 0.4393 - val_accuracy: 0.8148\n",
    "Epoch 14/30\n",
    "9/9 [==============================] - 3s 338ms/step - loss: 1.3621e-04 - accuracy: 1.0000 - val_loss: 0.4120 - val_accuracy: 0.8148\n",
    "Epoch 15/30\n",
    "9/9 [==============================] - 3s 347ms/step - loss: 4.5485e-04 - accuracy: 1.0000 - val_loss: 0.3815 - val_accuracy: 0.8333\n",
    "Epoch 16/30\n",
    "9/9 [==============================] - 3s 347ms/step - loss: 2.4808e-04 - accuracy: 1.0000 - val_loss: 0.3506 - val_accuracy: 0.8889\n",
    "Epoch 17/30\n",
    "9/9 [==============================] - 3s 341ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3259 - val_accuracy: 0.8889\n",
    "Epoch 18/30\n",
    "9/9 [==============================] - 3s 335ms/step - loss: 1.0890e-04 - accuracy: 1.0000 - val_loss: 0.3087 - val_accuracy: 0.8889\n",
    "Epoch 19/30\n",
    "9/9 [==============================] - 3s 329ms/step - loss: 2.1318e-04 - accuracy: 1.0000 - val_loss: 0.2900 - val_accuracy: 0.9259\n",
    "Epoch 20/30\n",
    "9/9 [==============================] - 3s 338ms/step - loss: 2.7181e-04 - accuracy: 1.0000 - val_loss: 0.2722 - val_accuracy: 0.9259\n",
    "Epoch 21/30\n",
    "9/9 [==============================] - 3s 345ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2516 - val_accuracy: 0.9444\n",
    "Epoch 22/30\n",
    "9/9 [==============================] - 3s 346ms/step - loss: 6.1500e-04 - accuracy: 1.0000 - val_loss: 0.2371 - val_accuracy: 0.9444\n",
    "Epoch 23/30\n",
    "9/9 [==============================] - 3s 353ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.2295 - val_accuracy: 0.9259\n",
    "Epoch 24/30\n",
    "9/9 [==============================] - 3s 336ms/step - loss: 4.1407e-04 - accuracy: 1.0000 - val_loss: 0.2172 - val_accuracy: 0.9259\n",
    "Epoch 25/30\n",
    "9/9 [==============================] - 3s 334ms/step - loss: 2.4711e-04 - accuracy: 1.0000 - val_loss: 0.2254 - val_accuracy: 0.9259\n",
    "Epoch 26/30\n",
    "9/9 [==============================] - 3s 327ms/step - loss: 3.4520e-04 - accuracy: 1.0000 - val_loss: 0.2332 - val_accuracy: 0.9259\n",
    "Epoch 27/30\n",
    "9/9 [==============================] - 3s 334ms/step - loss: 1.4777e-04 - accuracy: 1.0000 - val_loss: 0.2393 - val_accuracy: 0.9259\n",
    "Epoch 28/30\n",
    "9/9 [==============================] - 3s 344ms/step - loss: 2.9401e-04 - accuracy: 1.0000 - val_loss: 0.2433 - val_accuracy: 0.9259\n",
    "Epoch 29/30\n",
    "9/9 [==============================] - 3s 343ms/step - loss: 1.7767e-04 - accuracy: 1.0000 - val_loss: 0.2473 - val_accuracy: 0.9259\n",
    "Epoch 30/30\n",
    "9/9 [==============================] - 3s 348ms/step - loss: 9.3719e-05 - accuracy: 1.0000 - val_loss: 0.2535 - val_accuracy: 0.9259\n",
    "INFO:tensorflow:Assets written to: models/twin_net/assets\n",
    "Training Accuracy:  [0.04587867110967636, 0.987500011920929]\n",
    "2/2 [==============================] - 0s 93ms/step - loss: 0.1711 - accuracy: 0.9375\n",
    "Testing Accuracy:  [0.17109230160713196, 0.9375]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
