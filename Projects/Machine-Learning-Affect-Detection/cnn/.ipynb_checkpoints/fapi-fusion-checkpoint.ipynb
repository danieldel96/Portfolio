{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "painted-tonight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 128, 128, 16, 1)\n",
      "(320,)\n",
      "(320, 105211, 1)\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 105211, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 13152, 25)         1625      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 13152, 25)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 1644, 25)          80025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 1644, 25)          100       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 1644, 25)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 206, 25)           160025    \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 206, 25)           100       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 206, 25)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 52, 25)            320025    \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 52, 25)            100       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 52, 25)            0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)   (None, 52, 25)            0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1300)              0         \n",
      "=================================================================\n",
      "Total params: 562,000\n",
      "Trainable params: 561,850\n",
      "Non-trainable params: 150\n",
      "_________________________________________________________________\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 128, 128, 16, 1)] 0         \n",
      "_________________________________________________________________\n",
      "conv3d (Conv3D)              (None, 63, 63, 14, 64)    1792      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)   (None, 63, 63, 14, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 32, 32, 14, 128)   221312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 32, 32, 14, 128)   512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)   (None, 32, 32, 14, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 16, 16, 14, 256)   884992    \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 16, 16, 14, 256)   1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)   (None, 16, 16, 14, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 8, 8, 7, 512)      3539456   \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 8, 8, 7, 512)      2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)   (None, 8, 8, 7, 512)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 4, 4, 4, 1024)     14156800  \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 4, 4, 4, 1024)     4096      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)   (None, 4, 4, 4, 1024)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 2, 2, 2, 2048)     56625152  \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 2, 2, 2, 2048)     8192      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)   (None, 2, 2, 2, 2048)     0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 16384)             0         \n",
      "=================================================================\n",
      "Total params: 75,445,376\n",
      "Trainable params: 75,437,440\n",
      "Non-trainable params: 7,936\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n#audio neural network\\ndef audio_cnn_1d(sample_shape):\\n    #Layer 1\\n    model = Sequential()\\n    model.add(Conv1D(padding=\\'same\\', filters=25, kernel_size=64, strides = 8, input_shape=sample_shape))\\n    model.add(LeakyReLU(alpha=0.2))\\n\\n    #Layer 2\\n    model.add(Conv1D(padding=\\'same\\', filters=25, kernel_size=128, strides = 8))\\n    model.add(BatchNormalization())\\n    model.add(LeakyReLU(alpha=0.2))\\n\\n    #Layer 3\\n    model.add(Conv1D(padding=\\'same\\', filters=25, kernel_size=256, strides = 8))\\n    model.add(BatchNormalization())\\n    model.add(LeakyReLU(alpha=0.2))\\n\\n    #Layer 4\\n    model.add(Conv1D(padding=\\'same\\', filters=25, kernel_size=512, strides = 4))\\n    model.add(BatchNormalization())\\n    model.add(LeakyReLU(alpha=0.2))\\n\\n    #Layer 5\\n    model.add(Conv1D(padding=\\'same\\', filters=25, kernel_size=1024, strides = 4))\\n    model.add(BatchNormalization())\\n    model.add(LeakyReLU(alpha=0.2))\\n    \\n    #layer 6\\n    model.add(Flatten())\\n    return model\\n\\n#video neural network\\ndef video_cnn_3d(sample_shape):\\n    model = Sequential()\\n    #layer 1\\n    model.add(Conv3D(64, kernel_size=(3,3,3), strides=(2,2,1), input_shape=sample_shape))\\n    model.add(LeakyReLU(alpha=0.2))\\n    \\n    #layer 2\\n    model.add(Conv3D(128, kernel_size=(3,3,3), strides=(2,2,1), padding=\\'SAME\\'))\\n    model.add(BatchNormalization())\\n    model.add(LeakyReLU(alpha=0.2))\\n    \\n    #layer 3\\n    model.add(Conv3D(256, kernel_size=(3,3,3), strides=(2,2,1), padding=\\'SAME\\'))\\n    model.add(BatchNormalization())\\n    model.add(LeakyReLU(alpha=0.2))\\n\\n    #layer 4\\n    model.add(Conv3D(512, kernel_size=(3,3,3), strides=(2,2,2), padding=\\'SAME\\'))\\n    model.add(BatchNormalization())\\n    model.add(LeakyReLU(alpha=0.2))\\n\\n    #layer 5\\n    model.add(Conv3D(1024, kernel_size=(3,3,3), strides=(2,2,2), padding=\\'SAME\\'))\\n    model.add(BatchNormalization())\\n    model.add(LeakyReLU(alpha=0.2))\\n\\n    #layer 6\\n    model.add(Conv3D(2048, kernel_size=(3,3,3), strides=(2,2,2), padding=\\'SAME\\'))\\n    model.add(BatchNormalization())\\n    model.add(LeakyReLU(alpha=0.2))\\n\\n    #layer 7\\n    model.add(Flatten())\\n    return model\\n\\n#final fusion layer\\ndef fusion_cnn(input_shape):\\n    \\n    #fusion layer\\n    model = Sequential()\\n    model.add(Input(shape=input_shape))\\n    model.add(BatchNormalization())\\n    model.add(Dense(1,activation=\\'softmax\\'))\\n    return model\\n    \\n\\n#Setting up seperate networks for fusion\\nl_input = Input(audio_input) #tensor left = audio\\nl_base = audio_cnn_1d(audio_input) #model -> inputs into FM class # model #1\\nl_base.summary()\\n\\nr_input = Input(video_input) #tensor right = video (can be abstracted for any data type)\\nr_base = video_cnn_3d(video_input) #model -> inputs into FM class # model #2\\nr_base.summary()\\n\\n#encodings\\nl_encoded = l_base(l_input)\\nr_encoded = r_base(r_input)\\n\\nfusion_model_input = Concatenate()([l_encoded, r_encoded])\\n\\nfusion_model = fusion_cnn(fusion_model_input.shape[1]) # model #3\\nfusion_model.summary()\\n#########################################\\n\\n\\n#Combined fusion network into subclass\\nclass FM(tensorflow.keras.Model):\\n    def __init__(self, left, right, fusion, **kwargs):\\n        super(FM, self).__init__(**kwargs)\\n        self.left, self.right, self.fusion = left, right, fusion\\n        \\n    def train_step(self, data):\\n        x, y = data\\n        left_data, right_data = x\\n        with tensorflow.GradientTape() as tape:\\n            l = self.left(left_data)\\n            r = self.right(right_data)\\n            c = Concatenate()([l,r])\\n            y_pred = self.fusion(c)  # Forward pass\\n            loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\\n\\n        trainable_vars = self.trainable_variables\\n        gradients = tape.gradient(loss, trainable_vars)\\n        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\\n        self.compiled_metrics.update_state(y, y_pred)\\n        return {m.name: m.result() for m in self.metrics}\\n    \\n    def model(self):\\n        x = [ audio_input, video_input ]\\n        return \\n\\n    def call(self, data):\\n        left_data, right_data = data\\n        l = self.left(left_data)\\n        r = self.right(right_data)\\n        c = Concatenate()([l,r])\\n        y_pred = self.fusion(c)  # Forward pass\\n        return y_pred\\n####################################\\n    \\n#fusion model    \\nfusion_model = FM(l_base,r_base,fusion_model)\\n\\n\\n#train\\nfusion_model.compile(loss=\\'binary_crossentropy\\',\\n        optimizer=optimizers.Adam(lr=0.00001),metrics=[\\'accuracy\\'])\\n\\n\\nfusion_model.fit([a_train,v_train], l_train,\\n        batch_size=30,\\n        epochs=30,\\n        verbose=1,\\n        validation_split=0.166) #validation_split=0.3\\n\\nfusion_model.save(\\'models/fusion_model\\',save_format=\\'tf\\')\\n\\n\\n#test\\nmodel = load_model(\\'models/fusion_model\\')\\n\\n\\nscore = model.evaluate([a_train, v_train], l_train, verbose=0)\\nprint(\"Training Accuracy: \", score)\\n\\nscore = model.evaluate([a_test, v_test], l_test, verbose=1)\\nprint(\"Testing Accuracy: \", score)\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sequential model // doesnt work, refer to sequential vs. functional api\n",
    "#Functional api's handle multiple inputs better, sequential cannot create model with multiple inputs\n",
    "import keras\n",
    "import tensorflow\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import Conv3D\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers import Input\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "load = np.load('data/RAVDESS.npz')\n",
    "audio = load['audio']\n",
    "video = load['video']\n",
    "labels = load['labels']\n",
    "\n",
    "#video pre-process\n",
    "fraction = 5\n",
    "frames = int(80/fraction)\n",
    "shape = (128,128,frames,1)\n",
    "\n",
    "reshape_videos = []\n",
    "\n",
    "for i in video:\n",
    "    single_video = []\n",
    "    for j in range( i.shape[0] ): #HEREi.shape[0]\n",
    "        if(  j % fraction == 0 ):\n",
    "            single_video.append( i[j] )\n",
    "    reshape_videos.append( single_video )\n",
    "\n",
    "video = np.array(reshape_videos)\n",
    "del reshape_videos\n",
    "\n",
    "video_input = (128, 128, frames, 1)\n",
    "video_shape = (video.shape[0], 128, 128, frames, 1)\n",
    "video = np.reshape(video, video_shape)\n",
    "####################\n",
    "\n",
    "\n",
    "#audio pre-process\n",
    "num_rows = 105211\n",
    "num_columns = 1\n",
    "num_channels = 1\n",
    "\n",
    "audio_input = (num_rows, num_columns)\n",
    "audio_shape = (audio.shape[0], num_rows, num_columns)\n",
    "audio = np.reshape(audio, audio_shape)\n",
    "###################\n",
    "\n",
    "\n",
    "v_train, v_test, a_train, a_test, l_train, l_test = train_test_split(video, \n",
    "                                                                     audio, \n",
    "                                                                     labels,\n",
    "                                                                     test_size=0.166,\n",
    "                                                                     random_state=42) #size=0.2\n",
    "\n",
    "print(v_train.shape)\n",
    "print(l_train.shape)\n",
    "print(a_train.shape)\n",
    "\n",
    "\n",
    "def audio_cnn_1d(sample_shape):\n",
    "    #Layer 1\n",
    "    input_ = Input(shape=sample_shape)\n",
    "    conv1d = Conv1D(padding='same', filters=25, kernel_size=64, strides = 8, input_shape=sample_shape)(input_)\n",
    "    relu = LeakyReLU(alpha=0.2)(conv1d)\n",
    "    \n",
    "    #Layer 2\n",
    "    conv1d = Conv1D(padding='same', filters=25, kernel_size=128, strides = 8)(relu)\n",
    "    batch = BatchNormalization()(conv1d)\n",
    "    relu = LeakyReLU(alpha=0.2)(batch)\n",
    "    \n",
    "    #Layer 3\n",
    "    conv1d = Conv1D(padding='same', filters=25, kernel_size=256, strides = 8)(relu)\n",
    "    batch = BatchNormalization()(conv1d)\n",
    "    relu = LeakyReLU(alpha=0.2)(batch)\n",
    "    \n",
    "    #Layer 4\n",
    "    conv1d = Conv1D(padding='same', filters=25, kernel_size=512, strides = 4)(relu)\n",
    "    batch = BatchNormalization()(conv1d)\n",
    "    relu = LeakyReLU(alpha=0.2)(batch)\n",
    "    \n",
    "    #Layer 5\n",
    "    conv1d = Conv1D(padding='same', filters=25, kernel_size=1024, strides = 4)(relu)\n",
    "    batch = BatchNormalization()(conv1d)\n",
    "    relu = LeakyReLU(alpha=0.2)(relu)\n",
    "    \n",
    "    #layer 6\n",
    "    output = Flatten()(relu)\n",
    "    \n",
    "    model = Model(inputs=[input_], outputs=[output] )\n",
    "    return model\n",
    "\n",
    "#video neural network\n",
    "def video_cnn_3d(sample_shape):\n",
    "    input_ = Input(shape=sample_shape)\n",
    "    #layer 1\n",
    "    conv3d = Conv3D(64, kernel_size=(3,3,3), strides=(2,2,1), input_shape=sample_shape)(input_)\n",
    "    relu = LeakyReLU(alpha=0.2)(conv3d)\n",
    "    \n",
    "    #layer 2\n",
    "    conv3d = Conv3D(128, kernel_size=(3,3,3), strides=(2,2,1), padding='SAME')(relu)\n",
    "    batch = BatchNormalization()(conv3d)\n",
    "    relu = LeakyReLU(alpha=0.2)(batch)\n",
    "    \n",
    "    #layer 3\n",
    "    conv3d = Conv3D(256, kernel_size=(3,3,3), strides=(2,2,1), padding='SAME')(relu)\n",
    "    batch = BatchNormalization()(conv3d)\n",
    "    relu = LeakyReLU(alpha=0.2)(batch)\n",
    "\n",
    "    #layer 4\n",
    "    conv3d = Conv3D(512, kernel_size=(3,3,3), strides=(2,2,2), padding='SAME')(relu)\n",
    "    batch = BatchNormalization()(conv3d)\n",
    "    relu = LeakyReLU(alpha=0.2)(batch)\n",
    "\n",
    "    #layer 5\n",
    "    conv3d = Conv3D(1024, kernel_size=(3,3,3), strides=(2,2,2), padding='SAME')(relu)\n",
    "    batch = BatchNormalization()(conv3d)\n",
    "    relu = LeakyReLU(alpha=0.2)(batch)\n",
    "\n",
    "    #layer 6\n",
    "    conv3d = Conv3D(2048, kernel_size=(3,3,3), strides=(2,2,2), padding='SAME')(relu)\n",
    "    batch = BatchNormalization()(conv3d)\n",
    "    relu = LeakyReLU(alpha=0.2)(batch)\n",
    "\n",
    "    #layer 7\n",
    "    output = Flatten()(relu)\n",
    "    model = Model(inputs=[input_], outputs=[output] )\n",
    "    return model\n",
    "\n",
    "\n",
    "audio_model = audio_cnn_1d(audio_input)\n",
    "audio_model.summary()\n",
    "\n",
    "video_model = video_cnn_3d(video_input)\n",
    "video_model.summary()\n",
    "\n",
    "left_input = \n",
    "right_input = \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#final fusion layer\n",
    "def fusion_cnn(input_shape):\n",
    "    \n",
    "    #fusion layer\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1,activation='softmax'))\n",
    "    return model\n",
    "    \n",
    "\n",
    "#Setting up seperate networks for fusion\n",
    "l_input = Input(audio_input) #tensor left = audio\n",
    "l_base = audio_cnn_1d(audio_input) #model -> inputs into FM class # model #1\n",
    "l_base.summary()\n",
    "\n",
    "r_input = Input(video_input) #tensor right = video (can be abstracted for any data type)\n",
    "r_base = video_cnn_3d(video_input) #model -> inputs into FM class # model #2\n",
    "r_base.summary()\n",
    "\n",
    "#encodings\n",
    "l_encoded = l_base(l_input)\n",
    "r_encoded = r_base(r_input)\n",
    "\n",
    "fusion_model_input = Concatenate()([l_encoded, r_encoded])\n",
    "\n",
    "fusion_model = fusion_cnn(fusion_model_input.shape[1]) # model #3\n",
    "fusion_model.summary()\n",
    "#########################################\n",
    "\n",
    "\n",
    "#Combined fusion network into subclass\n",
    "class FM(tensorflow.keras.Model):\n",
    "    def __init__(self, left, right, fusion, **kwargs):\n",
    "        super(FM, self).__init__(**kwargs)\n",
    "        self.left, self.right, self.fusion = left, right, fusion\n",
    "        \n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "        left_data, right_data = x\n",
    "        with tensorflow.GradientTape() as tape:\n",
    "            l = self.left(left_data)\n",
    "            r = self.right(right_data)\n",
    "            c = Concatenate()([l,r])\n",
    "            y_pred = self.fusion(c)  # Forward pass\n",
    "            loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
    "\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "    \n",
    "    def model(self):\n",
    "        x = [ audio_input, video_input ]\n",
    "        return \n",
    "\n",
    "    def call(self, data):\n",
    "        left_data, right_data = data\n",
    "        l = self.left(left_data)\n",
    "        r = self.right(right_data)\n",
    "        c = Concatenate()([l,r])\n",
    "        y_pred = self.fusion(c)  # Forward pass\n",
    "        return y_pred\n",
    "####################################\n",
    "    \n",
    "#fusion model    \n",
    "fusion_model = FM(l_base,r_base,fusion_model)\n",
    "\n",
    "\n",
    "#train\n",
    "fusion_model.compile(loss='binary_crossentropy',\n",
    "        optimizer=optimizers.Adam(lr=0.00001),metrics=['accuracy'])\n",
    "\n",
    "\n",
    "fusion_model.fit([a_train,v_train], l_train,\n",
    "        batch_size=30,\n",
    "        epochs=30,\n",
    "        verbose=1,\n",
    "        validation_split=0.166) #validation_split=0.3\n",
    "\n",
    "fusion_model.save('models/fusion_model',save_format='tf')\n",
    "\n",
    "\n",
    "#test\n",
    "model = load_model('models/fusion_model')\n",
    "\n",
    "\n",
    "score = model.evaluate([a_train, v_train], l_train, verbose=0)\n",
    "print(\"Training Accuracy: \", score)\n",
    "\n",
    "score = model.evaluate([a_test, v_test], l_test, verbose=1)\n",
    "print(\"Testing Accuracy: \", score)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependent-beads",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
