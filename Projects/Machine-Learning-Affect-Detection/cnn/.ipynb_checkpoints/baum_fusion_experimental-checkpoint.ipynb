{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dirty-cradle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functional API fusion model\n",
    "import keras\n",
    "import tensorflow\n",
    "#tensorflow.debugging.set_log_device_placement(True)\n",
    "#print(\"Num GPUs Available: \", len(tensorflow.config.list_physical_devices('GPU')))\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import Conv3D\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers import Input\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import datetime\n",
    "from sklearn.model_selection import KFold\n",
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "import sys\n",
    "np.set_printoptions(threshold=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d85b3e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n"
     ]
    }
   ],
   "source": [
    "#gpus = tensorflow.config.list_physical_devices('GPU')\n",
    "\n",
    "\n",
    "strategy = tensorflow.distribute.MirroredStrategy(devices=[\"/gpu:2\",\"/gpu:3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "amended-malawi",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[520 115 128 128]\n"
     ]
    }
   ],
   "source": [
    "load = np.load('data/BAUM_basic.npz',allow_pickle=True)\n",
    "audio = load['audio']\n",
    "video = load['video']\n",
    "labels = load['labels']\n",
    "n_splits = 6\n",
    "print(np.array(video.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "direct-breath",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(520, 23, 128, 128, 1)\n",
      "(520, 128, 128, 23, 1)\n"
     ]
    }
   ],
   "source": [
    "#video pre-process\n",
    "\n",
    "fraction = 5\n",
    "frames = int(115/fraction) #115\n",
    "shape = (128,128,frames,1)\n",
    "\n",
    "video = np.reshape(video,(520, 115, 128, 128, 1))\n",
    "\n",
    "reshape_videos = []\n",
    "\n",
    "for i in video:\n",
    "    single_video = []\n",
    "    for j in range( i.shape[0] ): #HEREi.shape[0]\n",
    "        if(  j % fraction == 0 ):\n",
    "            single_video.append( i[j] )\n",
    "    reshape_videos.append( single_video )\n",
    "\n",
    "video = np.array(reshape_videos)\n",
    "del reshape_videos\n",
    "\n",
    "print(video.shape)\n",
    "\n",
    "video_input = (128, 128, frames, 1)\n",
    "video_shape = (video.shape[0], 128, 128, frames, 1)\n",
    "video = np.reshape(video, video_shape)\n",
    "print(video.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "broadband-financing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#audio pre-process\n",
    "num_rows = 84672\n",
    "num_columns = 1\n",
    "num_channels = 1\n",
    "\n",
    "audio_input = (num_rows, num_columns)\n",
    "audio_shape = (audio.shape[0], num_rows, num_columns)\n",
    "audio = np.reshape(audio, audio_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "regional-force",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nv_train, v_test, a_train, a_test, l_train, l_test = train_test_split(video, \\n                                                                     audio, \\n                                                                     labels,\\n                                                                     test_size=0.166,\\n                                                                     random_state=42) #size=0.2\\n\\nprint(v_train.shape)\\nprint(l_train[95])\\nprint(a_train.shape)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#labels = labels - 1\n",
    "#print(labels[101])\n",
    "labels = to_categorical(labels)\n",
    "target_names = ['neutral', 'calm', 'happy', 'sad', 'angry', 'fearful', 'disgust', 'surprised']\n",
    "\n",
    "\"\"\"\n",
    "v_train, v_test, a_train, a_test, l_train, l_test = train_test_split(video, \n",
    "                                                                     audio, \n",
    "                                                                     labels,\n",
    "                                                                     test_size=0.166,\n",
    "                                                                     random_state=42) #size=0.2\n",
    "\n",
    "print(v_train.shape)\n",
    "print(l_train[95])\n",
    "print(a_train.shape)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "unable-marina",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Audio Network\n",
    "def audio_cnn_1d(input_):\n",
    "    #Layer 1\n",
    "    conv1d = Conv1D(padding='same', filters=25, kernel_size=64, strides = 8, input_shape=audio_input)(input_)\n",
    "    relu = LeakyReLU(alpha=0.2)(conv1d)\n",
    "    \n",
    "    #Layer 2\n",
    "    conv1d = Conv1D(padding='same', filters=25, kernel_size=128, strides = 8)(relu)\n",
    "    batch = BatchNormalization()(conv1d)\n",
    "    relu = LeakyReLU(alpha=0.2)(batch)\n",
    "    \n",
    "    #Layer 3\n",
    "    conv1d = Conv1D(padding='same', filters=25, kernel_size=256, strides = 8)(relu)\n",
    "    batch = BatchNormalization()(conv1d)\n",
    "    relu = LeakyReLU(alpha=0.2)(batch)\n",
    "    \n",
    "    #Layer 4\n",
    "    conv1d = Conv1D(padding='same', filters=25, kernel_size=512, strides = 4)(relu)\n",
    "    batch = BatchNormalization()(conv1d)\n",
    "    relu = LeakyReLU(alpha=0.2)(batch)\n",
    "    \n",
    "    #Layer 5\n",
    "    conv1d = Conv1D(padding='same', filters=25, kernel_size=1024, strides = 4)(relu)\n",
    "    batch = BatchNormalization()(conv1d)\n",
    "    relu = LeakyReLU(alpha=0.2)(relu)\n",
    "    \n",
    "    #layer 6\n",
    "    output = Flatten()(relu)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "extreme-skirt",
   "metadata": {},
   "outputs": [],
   "source": [
    "#video neural network\n",
    "def video_cnn_3d(input_):\n",
    "    #layer 1\n",
    "    conv3d = Conv3D(64, kernel_size=(3,3,3), strides=(2,2,1), input_shape=video_input)(input_)\n",
    "    relu = LeakyReLU(alpha=0.2)(conv3d)\n",
    "    \n",
    "    #layer 2\n",
    "    conv3d = Conv3D(128, kernel_size=(3,3,3), strides=(2,2,1), padding='SAME')(relu)\n",
    "    batch = BatchNormalization()(conv3d)\n",
    "    relu = LeakyReLU(alpha=0.2)(batch)\n",
    "    \n",
    "    #layer 3\n",
    "    conv3d = Conv3D(256, kernel_size=(3,3,3), strides=(2,2,1), padding='SAME')(relu)\n",
    "    batch = BatchNormalization()(conv3d)\n",
    "    relu = LeakyReLU(alpha=0.2)(batch)\n",
    "\n",
    "    #layer 4\n",
    "    conv3d = Conv3D(512, kernel_size=(3,3,3), strides=(2,2,2), padding='SAME')(relu)\n",
    "    batch = BatchNormalization()(conv3d)\n",
    "    relu = LeakyReLU(alpha=0.2)(batch)\n",
    "\n",
    "    #layer 5\n",
    "    conv3d = Conv3D(1024, kernel_size=(3,3,3), strides=(2,2,2), padding='SAME')(relu)\n",
    "    batch = BatchNormalization()(conv3d)\n",
    "    relu = LeakyReLU(alpha=0.2)(batch)\n",
    "\n",
    "    #layer 6\n",
    "    conv3d = Conv3D(2048, kernel_size=(3,3,3), strides=(2,2,2), padding='SAME')(relu)\n",
    "    batch = BatchNormalization()(conv3d)\n",
    "    relu = LeakyReLU(alpha=0.2)(batch)\n",
    "\n",
    "    #layer 7\n",
    "    output = Flatten()(relu)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50b973a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=6, random_state=42, shuffle=True)\n",
      "(520, 84672, 1)\n",
      "(520, 6)\n",
      "Beginning fold #0...\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/duff/b/homes/RUIZLAB/danieldel/projects/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /s/duff/b/homes/RUIZLAB/danieldel/projects/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:5095: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "Epoch 1/300\n",
      "INFO:tensorflow:batch_all_reduce: 40 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 40 all-reduces with algorithm = nccl, num_packs = 1\n",
      "12/12 [==============================] - 33s 1s/step - loss: 2.4449 - accuracy: 0.2659 - val_loss: 2.3788 - val_accuracy: 0.1111\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 4s 377ms/step - loss: 0.6089 - accuracy: 0.7950 - val_loss: 2.5820 - val_accuracy: 0.1944\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 5s 378ms/step - loss: 0.1713 - accuracy: 0.9501 - val_loss: 2.6427 - val_accuracy: 0.1528\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 5s 380ms/step - loss: 0.0735 - accuracy: 0.9778 - val_loss: 2.5512 - val_accuracy: 0.1806\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 4s 370ms/step - loss: 0.0438 - accuracy: 0.9945 - val_loss: 2.5490 - val_accuracy: 0.1806\n",
      "INFO:tensorflow:Assets written to: models/baum_300_softmax/assets\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 0.0522 - accuracy: 0.9806 - val_loss: 2.6630 - val_accuracy: 0.1111\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 4s 363ms/step - loss: 0.0188 - accuracy: 0.9972 - val_loss: 2.7239 - val_accuracy: 0.0694\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 0.0261 - accuracy: 0.9972 - val_loss: 2.6590 - val_accuracy: 0.0833\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 4s 362ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 2.5996 - val_accuracy: 0.0694\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 0.0382 - accuracy: 0.9945 - val_loss: 2.6068 - val_accuracy: 0.0972\n",
      "INFO:tensorflow:Assets written to: models/baum_300_softmax/assets\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 0.0176 - accuracy: 0.9917 - val_loss: 2.5239 - val_accuracy: 0.0833\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 5s 402ms/step - loss: 0.0124 - accuracy: 0.9972 - val_loss: 2.4642 - val_accuracy: 0.1111\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 2.4171 - val_accuracy: 0.1111\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 4s 356ms/step - loss: 0.0162 - accuracy: 0.9945 - val_loss: 2.4477 - val_accuracy: 0.1389\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 4s 360ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 2.5058 - val_accuracy: 0.1389\n",
      "INFO:tensorflow:Assets written to: models/baum_300_softmax/assets\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 4s 363ms/step - loss: 0.0174 - accuracy: 0.9972 - val_loss: 2.3779 - val_accuracy: 0.1389\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 0.0346 - accuracy: 0.9917 - val_loss: 2.4694 - val_accuracy: 0.0972\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 4s 356ms/step - loss: 0.0301 - accuracy: 0.9917 - val_loss: 2.5731 - val_accuracy: 0.1250\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 4s 360ms/step - loss: 0.0117 - accuracy: 0.9972 - val_loss: 2.1969 - val_accuracy: 0.1111\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 0.0303 - accuracy: 0.9889 - val_loss: 2.6738 - val_accuracy: 0.1528\n",
      "INFO:tensorflow:Assets written to: models/baum_300_softmax/assets\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 4s 367ms/step - loss: 0.0539 - accuracy: 0.9889 - val_loss: 2.6403 - val_accuracy: 0.0972\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-9709e42f8808>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         twin_net.fit([a_train,v_train], l_train,\n\u001b[0m\u001b[1;32m     68\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m31\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1233\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m         \u001b[0mtraining_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/lib/python3.8/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m       \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/lib/python3.8/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m   2445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2446\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram_freq\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram_freq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2447\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2449\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings_freq\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings_freq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/lib/python3.8/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_log_weights\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m   2512\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2513\u001b[0m             \u001b[0mweight_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m':'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2514\u001b[0;31m             \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2516\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_weight_as_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/lib/python3.8/site-packages/tensorboard/plugins/histogram/summary_v2.py\u001b[0m in \u001b[0;36mhistogram\u001b[0;34m(name, data, step, buckets, description)\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mhistogram_summary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuckets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary_metadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         )\n\u001b[0;32m--> 145\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistogram_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuckets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary_metadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/lib/python3.8/site-packages/tensorboard/plugins/histogram/summary_v2.py\u001b[0m in \u001b[0;36mhistogram_summary\u001b[0;34m(data, buckets, histogram_metadata, step)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_buckets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuckets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             return tf.summary.write(\n\u001b[0m\u001b[1;32m    128\u001b[0m                 \u001b[0mtag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0mtensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlazy_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(tag, tensor, step, metadata, name)\u001b[0m\n\u001b[1;32m    760\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m     op = smart_cond.smart_cond(\n\u001b[0m\u001b[1;32m    763\u001b[0m         should_record_summaries(), record, _nothing, name=\"summary_cond\")\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/lib/python3.8/site-packages/tensorflow/python/framework/smart_cond.py\u001b[0m in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpred_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpred_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py\u001b[0m in \u001b[0;36mrecord\u001b[0;34m()\u001b[0m\n\u001b[1;32m    748\u001b[0m       \u001b[0;31m# Note the identity to move the tensor to the CPU.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m         summary_tensor = tensor() if callable(tensor) else array_ops.identity(\n\u001b[0m\u001b[1;32m    751\u001b[0m             tensor)\n\u001b[1;32m    752\u001b[0m         write_summary_op = gen_summary_ops.write_summary(\n",
      "\u001b[0;32m~/projects/lib/python3.8/site-packages/tensorboard/util/lazy_tensor_creator.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_CALL_IN_PROGRESS_SENTINEL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/lib/python3.8/site-packages/tensorboard/plugins/histogram/summary_v2.py\u001b[0m in \u001b[0;36mlazy_tensor\u001b[0;34m()\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;34m@\u001b[0m\u001b[0mlazy_tensor_creator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLazyTensorCreator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mlazy_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_buckets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuckets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             return tf.summary.write(\n",
      "\u001b[0;32m~/projects/lib/python3.8/site-packages/tensorboard/plugins/histogram/summary_v2.py\u001b[0m in \u001b[0;36m_buckets\u001b[0;34m(data, bucket_count)\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebugging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbucket_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebugging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbucket_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# flatten\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0mis_empty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mHas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m   \"\"\"\n\u001b[0;32m--> 196\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m   \u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_set_static_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/lib/python3.8/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m   8396\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8397\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8398\u001b[0;31m       return reshape_eager_fallback(\n\u001b[0m\u001b[1;32m   8399\u001b[0m           tensor, shape, name=name, ctx=_ctx)\n\u001b[1;32m   8400\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/lib/python3.8/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mreshape_eager_fallback\u001b[0;34m(tensor, shape, name, ctx)\u001b[0m\n\u001b[1;32m   8417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8418\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mreshape_eager_fallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8419\u001b[0;31m   \u001b[0m_attr_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs_to_matching_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8420\u001b[0m   \u001b[0m_attr_Tshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs_to_matching_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8421\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36margs_to_matching_eager\u001b[0;34m(l, ctx, allowed_dtypes, default_dtype)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         tensor = ops.convert_to_tensor(\n\u001b[0m\u001b[1;32m    274\u001b[0m             t, dtype, preferred_dtype=default_dtype, ctx=ctx)\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/lib/python3.8/site-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1566\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/lib/python3.8/site-packages/tensorflow/python/distribute/values.py\u001b[0m in \u001b[0;36m_tensor_conversion_distributed_var\u001b[0;34m(var, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m   1374\u001b[0m def _tensor_conversion_distributed_var(var, dtype=None, name=None,\n\u001b[1;32m   1375\u001b[0m                                        as_ref=False):\n\u001b[0;32m-> 1376\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_var_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/lib/python3.8/site-packages/tensorflow/python/distribute/values.py\u001b[0m in \u001b[0;36m_dense_var_to_tensor\u001b[0;34m(self, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m   1173\u001b[0m           \"using variable.read_value(), or switch to TF 2.x.\")\n\u001b[1;32m   1174\u001b[0m     return ops.convert_to_tensor(\n\u001b[0;32m-> 1175\u001b[0;31m         self._get(), dtype=dtype, name=name, as_ref=as_ref)\n\u001b[0m\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/lib/python3.8/site-packages/tensorflow/python/distribute/values.py\u001b[0m in \u001b[0;36m_get\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    739\u001b[0m     \u001b[0mreplica_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_current_replica_id_as_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreplica_id\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_cross_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    742\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplica_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/lib/python3.8/site-packages/tensorflow/python/distribute/values.py\u001b[0m in \u001b[0;36m_get_cross_replica\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1117\u001b[0m     \u001b[0;31m# Return identity, to avoid directly exposing the variable to the user and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;31m# allowing it to be modified by mistake.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1119\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMirrored\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_cross_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_as_graph_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36midentity\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;31m# variables. Variables have correct handle data when graph building.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m   \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m   \u001b[0;31m# Propagate handle data for happier shape inference for resource variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_handle_data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/lib/python3.8/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36midentity\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m   3930\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3931\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3932\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   3933\u001b[0m         _ctx, \"Identity\", name, input)\n\u001b[1;32m   3934\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#k-Fold training, set for 6 splits\n",
    "\n",
    "n = 0 #current fold\n",
    "\n",
    "epochs = 30\n",
    "function = 'softmax'\n",
    "name = 'baum_' + str(epochs) + '_' + function \n",
    "pickle_file = 'pickle_files/' + name + '.pckl'\n",
    "\n",
    "training_score = []\n",
    "testing_score = []\n",
    "\n",
    "f = open(pickle_file, 'wb') #file for saving information/data about each fold\n",
    "\n",
    "\n",
    "kf = KFold(n_splits,shuffle=True,random_state=42)\n",
    "kf.get_n_splits(audio)\n",
    "\n",
    "print(kf)\n",
    "\n",
    "print(audio.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "kf = KFold(n_splits,shuffle=True,random_state=42)\n",
    "kf.get_n_splits(audio)\n",
    "\n",
    "for train_index, test_index in kf.split(audio):\n",
    "    print('Beginning fold #' + str(n) + '...')\n",
    "    #print(train_index)\n",
    "    #print(test_index)\n",
    "    a_train, a_test = audio[train_index], audio[test_index]\n",
    "    v_train, v_test = video[train_index], video[test_index]\n",
    "    l_train, l_test = labels[train_index], labels[test_index]\n",
    "    \n",
    "    \n",
    "    with strategy.scope():\n",
    "        #fusion layer\n",
    "        aud = Input(audio_input)\n",
    "        vid = Input(video_input)\n",
    "\n",
    "        audio_tensor = audio_cnn_1d(aud)\n",
    "\n",
    "        video_tensor = video_cnn_3d(vid)\n",
    "\n",
    "        fusion = Concatenate()([audio_tensor, video_tensor]) #combining tensors\n",
    "        batch = BatchNormalization()(fusion)\n",
    "        prediction = Dense(6,activation=function)(batch) #softmax\n",
    "        twin_net = Model(inputs=[aud,vid], outputs=prediction)\n",
    "\n",
    "        #Training\n",
    "\n",
    "        checkpoint_filepath = 'models/' + name\n",
    "        model_checkpoint_callback = ModelCheckpoint(\n",
    "            filepath=checkpoint_filepath,\n",
    "            period=5\n",
    "            )\n",
    "        log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + checkpoint_filepath\n",
    "        tensorboard_callback = tensorflow.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "        twin_net.compile(loss='categorical_crossentropy', #categorical_crossentropy\n",
    "                optimizer=optimizers.Adam(lr=0.00001), \n",
    "                         metrics=['accuracy'])\n",
    "\n",
    "        #twin_net.summary()\n",
    "\n",
    "\n",
    "        twin_net.fit([a_train,v_train], l_train,\n",
    "                batch_size=31,\n",
    "                epochs=epochs,\n",
    "                verbose=1,\n",
    "                validation_split=0.166,\n",
    "                callbacks=[model_checkpoint_callback,\n",
    "                tensorboard_callback])\n",
    "        \n",
    "        score = twin_net.evaluate([a_train, v_train], l_train, verbose=0)\n",
    "        pickle.dump([score, 'training accuracy fold #' + str(n)], f)\n",
    "        training_score.append(score)\n",
    "\n",
    "        score = twin_net.evaluate([a_test, v_test], l_test, verbose=0)\n",
    "        pickle.dump([score, 'testing accuracy fold #' + str(n)], f)\n",
    "        testing_score.append(score)\n",
    "\n",
    "        Y_pred = twin_net.predict([a_test, v_test])\n",
    "        y_pred = np.argmax(Y_pred, axis=1)\n",
    "        labels_ = np.argmax(l_test, axis=1)\n",
    "        pickle.dump(confusion_matrix(labels_, y_pred), f)\n",
    "        pickle.dump(classification_report(labels_, y_pred), f)\n",
    "        \n",
    "        n+=1\n",
    "\n",
    "np.savez('data/'+name,x=training_score,y=testing_score)\n",
    "f.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3fe35d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.22613226 0.87297922]\n",
      " [0.23712194 0.87528867]\n",
      " [0.24045701 0.87990761]\n",
      " [0.28069293 0.87066972]\n",
      " [0.25392863 0.86866361]\n",
      " [0.2732116  0.88018435]] [[1.6509198  0.31034482]\n",
      " [1.51186502 0.43678162]\n",
      " [1.51195204 0.41379312]\n",
      " [1.71064496 0.37931034]\n",
      " [1.72318459 0.36046511]\n",
      " [1.59833682 0.3488372 ]]\n"
     ]
    }
   ],
   "source": [
    "load = np.load('data/'+name+'.npz')\n",
    "training_score = load['x']\n",
    "testing_score = load['y']\n",
    "\n",
    "print(training_score,testing_score)\n",
    "\n",
    "f.close()\n",
    "\n",
    "with (open(pickle_file, \"rb\")) as openfile:\n",
    "    while True:\n",
    "        try:\n",
    "            print(pickle.load(openfile))\n",
    "        except EOFError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d2ce20",
   "metadata": {},
   "outputs": [],
   "source": [
    "soft 300 epoch\n",
    "Training Accuracy:  [1.4789059162139893, 0.9099307060241699]\n",
    "Testing Accuracy:  [11.502437591552734, 0.4137931168079376]\n",
    "Confusion_Matrix\n",
    "[[ 0  1  0  0  2  0]\n",
    " [ 2  6  0  6  4  1]\n",
    " [ 0  1  1  1  1  1]\n",
    " [ 2  6  0 16  6  1]\n",
    " [ 3  1  0  2 11  2]\n",
    " [ 0  1  0  3  4  2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b81956",
   "metadata": {},
   "source": [
    "sig 300 epoch\n",
    "Training Accuracy:  [0.12294566631317139, 0.912240207195282]\n",
    "Testing Accuracy:  [1.0002453327178955, 0.4252873659133911]\n",
    "Confusion_Matrix\n",
    "[[ 0  1  0  0  2  0]\n",
    " [ 1  5  1  7  5  0]\n",
    " [ 0  1  2  1  1  0]\n",
    " [ 2  5  1 18  4  1]\n",
    " [ 3  0  0  4 11  1]\n",
    " [ 2  1  0  2  4  1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd487b7f",
   "metadata": {},
   "source": [
    "baum basic 6 softmax\n",
    "Training Accuracy:  [0.459194540977478, 0.9053117632865906]\n",
    "Testing Accuracy:  [3.032977819442749, 0.3563218414783478]\n",
    "Confusion_Matrix\n",
    "[[ 0  0  0  0  2  1]\n",
    " [ 1  3  0  9  3  3]\n",
    " [ 0  1  1  1  1  1]\n",
    " [ 1  4  2 20  4  0]\n",
    " [ 5  2  0  4  6  2]\n",
    " [ 1  1  0  4  3  1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442e15c3",
   "metadata": {},
   "source": [
    "Baum basic 6 sigmoid\n",
    "Training Accuracy:  [0.27888423204421997, 0.9053117632865906]\n",
    "Testing Accuracy:  [0.9529832601547241, 0.40229883790016174]\n",
    "Confusion_Matrix\n",
    "[[ 0  1  0  1  1  0]\n",
    " [ 1  5  1  7  4  1]\n",
    " [ 0  1  2  1  1  0]\n",
    " [ 2  6  3 17  2  1]\n",
    " [ 4  0  0  4  9  2]\n",
    " [ 0  1  0  4  3  2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7994fe",
   "metadata": {},
   "source": [
    "Baum all\n",
    "Training Accuracy:  [0.27805307507514954, 0.8719576597213745]\n",
    "Testing Accuracy:  [0.8749507665634155, 0.24338623881340027]\n",
    "Confusion_Matrix\n",
    "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
    " [ 0  0  0  1  0  0  0  1  3  1  2  1  0  0]\n",
    " [ 0  0  2  0  0  0  0  1  0  0  0  0  0  0]\n",
    " [ 0  0  1  1  0  1  2  1  2  3  4  0  2  0]\n",
    " [ 0  0  0  0  2  0  1  0  0  0  0  0  0  3]\n",
    " [ 0  0  0  0  0  1  0  0  0  0  0  0  1  0]\n",
    " [ 0  0  1  1  0  0  4  2  1  1  2  0  0  0]\n",
    " [ 0  0  2  0  0  0  0  1  0  1  2  0  0  0]\n",
    " [ 1  4  0  0  1  1  4  1  9  3  2  0  3  0]\n",
    " [ 0  0  1  1  1  0  2  1  2 10  2  2  4  3]\n",
    " [ 0  3  0  0  0  0  4  0  1  5  7  2  0  1]\n",
    " [ 0  2  1  1  0  0  3  1  1  0  0  0  0  1]\n",
    " [ 0  0  0  1  2  1  0  2  1  7  3  2  3  2]\n",
    " [ 0  0  0  0  0  0  2  0  0  2  6  1  2  6]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
